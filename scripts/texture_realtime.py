#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶çº¹ç†åŒ– - å¸¦è½¨è¿¹éªŒè¯çš„OpenMVSå¢å¼ºç‰ˆ
============================================================================
åˆ†ä¸¤ä¸ªé˜¶æ®µï¼š
1. è½¨è¿¹éªŒè¯é˜¶æ®µï¼šæ˜¾ç¤ºè½¨è¿¹ï¼Œå…è®¸äº¤äº’å¼è°ƒæ•´ï¼ˆå‚è€ƒ verify_trajectory_from_txt.pyï¼‰
2. çº¹ç†åŒ–é˜¶æ®µï¼šç¡®è®¤è½¨è¿¹åå¼€å§‹å®æ—¶çº¹ç†åŒ–

ä½¿ç”¨ OpenCV æ ‡å‡†ç›¸æœºåæ ‡ç³»ï¼ˆæ— é¢å¤–å˜æ¢ï¼‰
"""
import sys
import os
from pathlib import Path

# Windows: æ·»åŠ NVIDIA DLLç›®å½•ï¼ˆGPUåŠ é€Ÿæ‰€éœ€ï¼‰
if os.name == 'nt':
    user_site = Path(os.path.expanduser('~')) / 'AppData' / 'Roaming' / 'Python' / f'Python{sys.version_info.major}{sys.version_info.minor}' / 'site-packages'
    nvidia_dir = user_site / 'nvidia'
    if nvidia_dir.exists():
        for pkg_dir in nvidia_dir.iterdir():
            if pkg_dir.is_dir():
                bin_dir = pkg_dir / 'bin'
                if bin_dir.exists() and hasattr(os, 'add_dll_directory'):
                    os.add_dll_directory(str(bin_dir))

if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import open3d as o3d
import numpy as np
import cv2
from scipy.spatial.transform import Rotation as R
import time
import threading
from collections import deque
from datetime import datetime
import yaml
import argparse

# GPUåŠ é€Ÿæ”¯æŒ
try:
    import cupy as cp
    GPU_AVAILABLE = cp.cuda.is_available()
    if GPU_AVAILABLE:
        GPU_DEVICE_COUNT = cp.cuda.runtime.getDeviceCount()
except ImportError:
    cp = None
    GPU_AVAILABLE = False
    GPU_DEVICE_COUNT = 0

print("="*70)
print("å®æ—¶çº¹ç†åŒ– - å¸¦è½¨è¿¹éªŒè¯çš„OpenMVSå¢å¼ºç‰ˆ (GPUåŠ é€Ÿ)")
print("="*70)

# ============================================================================
# å‘½ä»¤è¡Œå‚æ•°è§£æ
# ============================================================================
parser = argparse.ArgumentParser(description='å®æ—¶çº¹ç†åŒ–ç¨‹åº')
parser.add_argument('--config', type=str, default=None, 
                    help='é…ç½®æ–‡ä»¶è·¯å¾„ (YAMLæ ¼å¼ï¼Œä¾‹å¦‚ï¼šconfig_ground_clarity.yaml)')
args = parser.parse_args()

# ============================================================================
# åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
# ============================================================================
def load_config(config_path):
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"\nâœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    return config

if args.config:
    cfg = load_config(args.config)
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
else:
    cfg = None
    print("ğŸ“ ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆä»£ç ä¸­çš„å‚æ•°ï¼‰")

# ============================================================================
# é…ç½®ï¼ˆä»YAMLåŠ è½½æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
# ============================================================================
mesh_path = cfg['paths']['mesh_path'] if cfg else "Datasets/eslam_data/tiles/mesh_tile_00.ply"
pose_dir = cfg['paths']['pose_dir'] if cfg else "Datasets/eslam_data/pose"
first_pose_txt = cfg['paths']['first_pose_txt'] if cfg else "Datasets/eslam_data/first_pose_osm.txt"
K_npz = cfg['paths']['K_npz'] if cfg else "Datasets/eslam_data/K_rectified.npz"
rgb_dir = cfg['paths']['rgb_dir'] if cfg else "Datasets/eslam_data/color"
depth_dir = cfg['paths']['depth_dir'] if cfg else "Datasets/eslam_data/depth"

# å¯è§†åŒ–å‚æ•°
SAMPLE_RATE = cfg['visualization']['sample_rate'] if cfg else 20
ARROW_SCALE = cfg['visualization']['arrow_scale'] if cfg else 1.0
ARROW_LENGTH = cfg['visualization']['arrow_length'] if cfg else 2.0
SHOW_CAMERA_FRUSTUM = cfg['visualization']['show_camera_frustum'] if cfg else True
VISUALIZATION_UPDATE_RATE = cfg['visualization']['update_rate'] if cfg else 10

# çº¹ç†åŒ–å‚æ•°
FRAME_SAMPLE_RATE = cfg['texturing']['frame_sample_rate'] if cfg else 1
MAX_IMAGES = cfg['texturing']['max_images'] if cfg else 10000
UPDATE_INTERVAL = cfg['texturing']['update_interval'] if cfg else 0.01

# OpenMVSå¢å¼ºå‚æ•°
DEPTH_THRESHOLD = cfg['openmvs']['depth_threshold'] if cfg else 1.5
DEPTH_SCALE = cfg['openmvs']['depth_scale'] if cfg else 1000.0
MIN_DEPTH = cfg['openmvs']['min_depth'] if cfg else 0.1
MAX_DEPTH = cfg['openmvs']['max_depth'] if cfg else 20.0
ANGLE_THRESHOLD_DEG = cfg['openmvs']['angle_threshold_deg'] if cfg else 360
USE_DEPTH_CONSISTENCY = cfg['openmvs']['use_depth_consistency'] if cfg else True
USE_ANGLE_WEIGHTING = cfg['openmvs']['use_angle_weighting'] if cfg else False
USE_EXPOSURE_COMP = cfg['openmvs']['use_exposure_comp'] if cfg else True
DEBUG_MODE = cfg['openmvs']['debug_mode'] if cfg else True

# è‡ªé€‚åº”æ·±åº¦æ£€æµ‹å‚æ•°ï¼ˆæ–°å¢ï¼‰
USE_ADAPTIVE_DEPTH = cfg['openmvs'].get('use_adaptive_depth', False) if cfg else False
FLOOR_NORMAL_THRESHOLD = cfg['openmvs'].get('floor_normal_threshold', 0.7) if cfg else 0.7
FLOOR_DEPTH_FRONT = cfg['openmvs'].get('floor_depth_front', 0.3) if cfg else 0.3
FLOOR_DEPTH_BACK = cfg['openmvs'].get('floor_depth_back', 0.08) if cfg else 0.08
WALL_DEPTH_FRONT = cfg['openmvs'].get('wall_depth_front', 0.5) if cfg else 0.5
WALL_DEPTH_BACK = cfg['openmvs'].get('wall_depth_back', 0.15) if cfg else 0.15

# ============================================================================
# è½¦è¾†æ£€æµ‹å‚æ•°ï¼ˆå››æ¨¡æ€å‡ ä½•æ£€æµ‹ï¼‰
# ============================================================================
if cfg and 'vehicle_detection' in cfg:
    vd_cfg = cfg['vehicle_detection']
    USE_VEHICLE_DETECTION = vd_cfg.get('enable', False)
    # 1. æ³•å‘æ£€æµ‹
    USE_GROUND_NORMAL = vd_cfg.get('use_ground_normal', True)
    GROUND_NORMAL_THRESHOLD = vd_cfg.get('ground_normal_threshold', 0.94)
    # 2. é«˜åº¦è¿‡æ»¤
    USE_HEIGHT_FILTER = vd_cfg.get('use_height_filter', True)
    VEHICLE_HEIGHT_MIN = vd_cfg.get('vehicle_height_min', 0.5)
    VEHICLE_HEIGHT_MAX = vd_cfg.get('vehicle_height_max', 2.5)
    # 3. æ·±åº¦ä¸è¿ç»­
    USE_DEPTH_DISCONTINUITY = vd_cfg.get('use_depth_discontinuity', True)
    DEPTH_GRADIENT_THRESHOLD = vd_cfg.get('depth_gradient_threshold', 1.0)
    # 4. TSDFæ·±åº¦ä¸€è‡´æ€§ï¼ˆæ–°å¢ï¼ï¼‰
    USE_TSDF_DEPTH_CONSISTENCY = vd_cfg.get('use_depth_consistency', False)
    DEPTH_DIFF_THRESHOLD = vd_cfg.get('depth_diff_threshold', 0.3)
    DEPTH_NOISE_TOLERANCE = vd_cfg.get('depth_noise_tolerance', 0.05)
    # ç»¼åˆè®¾ç½®
    REQUIRE_ALL_CUES = vd_cfg.get('require_all_cues', True)
    VEHICLE_MASK_DILATION = vd_cfg.get('mask_dilation', 5)
    SAVE_VEHICLE_MASKS = vd_cfg.get('save_masks', False)
else:
    # é»˜è®¤å…³é—­
    USE_VEHICLE_DETECTION = False
    USE_GROUND_NORMAL = True
    GROUND_NORMAL_THRESHOLD = 0.94
    USE_HEIGHT_FILTER = True
    VEHICLE_HEIGHT_MIN = 0.5
    VEHICLE_HEIGHT_MAX = 2.5
    USE_DEPTH_DISCONTINUITY = True
    DEPTH_GRADIENT_THRESHOLD = 1.0
    USE_TSDF_DEPTH_CONSISTENCY = False
    DEPTH_DIFF_THRESHOLD = 0.3
    DEPTH_NOISE_TOLERANCE = 0.05
    REQUIRE_ALL_CUES = True
    VEHICLE_MASK_DILATION = 5
    SAVE_VEHICLE_MASKS = False

# å‘åå…¼å®¹æ—§å‚æ•°
USE_VEHICLE_REMOVAL = USE_VEHICLE_DETECTION

# å›ºå®šé«˜åº¦å‚æ•°
FIX_CAMERA_HEIGHT = cfg['camera']['fix_camera_height'] if cfg else True
FIXED_HEIGHT = cfg['camera']['fixed_height'] if cfg else None
# å¼ºåˆ¶ç›¸æœºæ°´å¹³å‚æ•°ï¼ˆæ–°å¢ï¼‰
FORCE_CAMERA_HORIZONTAL = cfg['camera'].get('force_camera_horizontal', False) if cfg else False

# åå¤„ç†å‚æ•°ï¼šç©ºç™½åŒºåŸŸå¡«å……
FILL_EMPTY_VERTICES = cfg.get('post_processing', {}).get('fill_empty_vertices', False) if cfg else False
FILL_METHOD = cfg.get('post_processing', {}).get('fill_method', 'knn') if cfg else 'knn'
KNN_NEIGHBORS = cfg.get('post_processing', {}).get('knn_neighbors', 8) if cfg else 8

# æ¨¡å‹ä¿å­˜å‚æ•°
SAVE_TEXTURED_MESH = cfg.get('output', {}).get('save_textured_mesh', True) if cfg else True
OUTPUT_DIR = cfg.get('output', {}).get('output_dir', 'output/textured_meshes') if cfg else 'output/textured_meshes'
OUTPUT_FILENAME = cfg.get('output', {}).get('output_filename', 'textured_mesh.ply') if cfg else 'textured_mesh.ply'
AUTO_TIMESTAMP = cfg.get('output', {}).get('auto_timestamp', True) if cfg else True

# GPUåŠ é€Ÿå‚æ•°
USE_GPU = cfg['gpu']['use_gpu'] if cfg else True
GPU_DEVICE_ID = cfg['gpu']['device_id'] if cfg else 0

# æ—‹è½¬é…ç½®ä¿å­˜/åŠ è½½
ROTATION_CONFIG_FILE = cfg['rotation']['config_file'] if cfg else "Datasets/eslam_data/rotation_config.json"
AUTO_LOAD_ROTATION = cfg['rotation']['auto_load'] if cfg else True
DEFAULT_ROTATION = tuple(cfg['rotation']['default_rotation']) if cfg else (180, 0, 0)

# ============================================================================
# çº¹ç†è´¨é‡å¢å¼ºå‚æ•° - ç¬¬1æ­¥ï¼šå›¾åƒè´¨é‡è¯„ä¼°ä¸è¿‡æ»¤
# ============================================================================
USE_IMAGE_QUALITY_FILTER = cfg['step1_quality_filter']['enable'] if cfg else True
IMAGE_QUALITY_THRESHOLD = cfg['step1_quality_filter']['quality_threshold'] if cfg else 30.0
SHARPNESS_THRESHOLD = cfg['step1_quality_filter']['sharpness_threshold'] if cfg else 30.0
MAX_OVEREXPOSURE = cfg['step1_quality_filter']['max_overexposure'] if cfg else 0.15
MAX_UNDEREXPOSURE = cfg['step1_quality_filter']['max_underexposure'] if cfg else 0.15
SHOW_QUALITY_STATS = cfg['step1_quality_filter']['show_quality_stats'] if cfg else True

# ============================================================================
# çº¹ç†è´¨é‡å¢å¼ºå‚æ•° - ç¬¬2æ­¥ï¼šå›¾åƒé¢„å¤„ç†å¢å¼º
# ============================================================================
USE_IMAGE_ENHANCEMENT = cfg['step2_image_enhancement']['enable'] if cfg else True
USE_UNSHARP_MASK = cfg['step2_image_enhancement']['use_unsharp_mask'] if cfg else True
UNSHARP_RADIUS = cfg['step2_image_enhancement']['unsharp_radius'] if cfg else 2.0
UNSHARP_AMOUNT = cfg['step2_image_enhancement']['unsharp_amount'] if cfg else 1.5
USE_BILATERAL_FILTER = cfg['step2_image_enhancement']['use_bilateral_filter'] if cfg else True
BILATERAL_D = cfg['step2_image_enhancement']['bilateral_d'] if cfg else 5
BILATERAL_SIGMA_COLOR = cfg['step2_image_enhancement']['bilateral_sigma_color'] if cfg else 75
BILATERAL_SIGMA_SPACE = cfg['step2_image_enhancement']['bilateral_sigma_space'] if cfg else 75
USE_CLAHE = cfg['step2_image_enhancement']['use_clahe'] if cfg else True
CLAHE_CLIP_LIMIT = cfg['step2_image_enhancement']['clahe_clip_limit'] if cfg else 2.0
CLAHE_TILE_SIZE = cfg['step2_image_enhancement']['clahe_tile_size'] if cfg else 8

# ç¬¬3æ­¥ä¼˜åŒ–å‚æ•°ï¼šåŒä¸‰æ¬¡æ’å€¼
USE_BICUBIC_INTERPOLATION = cfg['step3_bicubic']['enable'] if cfg else True
BICUBIC_A = cfg['step3_bicubic']['bicubic_a'] if cfg else -0.5

# ç¬¬4æ­¥ä¼˜åŒ–å‚æ•°ï¼šæ™ºèƒ½è§†è§’é€‰æ‹©ä¸åŠ æƒ
USE_SMART_VIEW_WEIGHTING = cfg['step4_view_weighting']['enable'] if cfg else True
VIEW_ANGLE_WEIGHT = cfg['step4_view_weighting']['view_angle_weight'] if cfg else 0.4
DISTANCE_WEIGHT = cfg['step4_view_weighting']['distance_weight'] if cfg else 0.3
IMAGE_QUALITY_WEIGHT = cfg['step4_view_weighting']['image_quality_weight'] if cfg else 0.3
MAX_VIEW_ANGLE_DEG = cfg['step4_view_weighting']['max_view_angle_deg'] if cfg else 75.0
DISTANCE_FALLOFF = cfg['step4_view_weighting']['distance_falloff'] if cfg else 2.0
MIN_EFFECTIVE_WEIGHT = cfg['step4_view_weighting']['min_effective_weight'] if cfg else 0.1

# ---------- ç¬¬5æ­¥ä¼˜åŒ–ï¼šæ¥ç¼å¹³æ»‘é…ç½® ----------
USE_SEAM_SMOOTHING = cfg['step5_seam_smoothing']['enable'] if cfg else True
VARIANCE_THRESHOLD = cfg['step5_seam_smoothing']['variance_threshold'] if cfg else 0.01
SMOOTHING_STRENGTH = cfg['step5_seam_smoothing']['smoothing_strength'] if cfg else 0.5
SEAM_K_NEIGHBORS = cfg['step5_seam_smoothing']['k_neighbors'] if cfg else 15

# ---------- ç¬¬6æ­¥ä¼˜åŒ–ï¼šLABè‰²å½©ç©ºé—´é…ç½® ----------
USE_LAB_COLOR_SPACE = cfg['step6_lab_color']['enable'] if cfg else True
LAB_L_WEIGHT = cfg['step6_lab_color']['l_weight'] if cfg else 0.5
LAB_NORMALIZE_L = cfg['step6_lab_color']['normalize_l'] if cfg else True
LAB_L_CLIP_PERCENTILE = cfg['step6_lab_color']['l_clip_percentile'] if cfg else 2.0

# ---------- ç¬¬7æ­¥ä¼˜åŒ–ï¼šäºšåƒç´ ç²¾åº¦æŠ•å½±é…ç½® ----------
USE_SUBPIXEL_PRECISION = cfg['step7_subpixel']['enable'] if cfg else True
USE_FLOAT64_PROJECTION = cfg['step7_subpixel']['use_float64'] if cfg else True
SUBPIXEL_WEIGHT_MODE = cfg['step7_subpixel']['weight_mode'] if cfg else "bilinear"
PRESERVE_SUBPIXEL_WEIGHT = cfg['step7_subpixel']['preserve_weight'] if cfg else True
PROJECTION_EPSILON = cfg['step7_subpixel']['projection_epsilon'] if cfg else 1e-10

# ---------- ç¬¬8æ­¥ä¼˜åŒ–ï¼šçº¹ç†åå¤„ç†é…ç½® ----------
USE_POST_PROCESSING = cfg['step8_post_processing']['enable'] if cfg else True
# å¼‚å¸¸å€¼æ£€æµ‹
USE_OUTLIER_DETECTION = cfg['step8_post_processing']['outlier_detection']['enable'] if cfg else True
OUTLIER_DETECTION_METHOD = cfg['step8_post_processing']['outlier_detection']['method'] if cfg else "both"
OUTLIER_ZSCORE_THRESHOLD = cfg['step8_post_processing']['outlier_detection']['zscore_threshold'] if cfg else 3.0
OUTLIER_LOCAL_WINDOW = cfg['step8_post_processing']['outlier_detection']['local_window'] if cfg else 5
OUTLIER_LOCAL_THRESHOLD = cfg['step8_post_processing']['outlier_detection']['local_threshold'] if cfg else 2.5
# è¾¹ç¼˜ä¿æŒå¹³æ»‘
USE_EDGE_PRESERVING_SMOOTH = cfg['step8_post_processing']['edge_preserving']['enable'] if cfg else True
SMOOTH_METHOD = cfg['step8_post_processing']['edge_preserving']['method'] if cfg else "bilateral"
BILATERAL_SIGMA_SPATIAL = cfg['step8_post_processing']['edge_preserving']['bilateral_sigma_spatial'] if cfg else 5.0
BILATERAL_SIGMA_COLOR = cfg['step8_post_processing']['edge_preserving']['bilateral_sigma_color'] if cfg else 25.0
ANISOTROPIC_ITERATIONS = cfg['step8_post_processing']['edge_preserving']['anisotropic_iterations'] if cfg else 10
ANISOTROPIC_KAPPA = cfg['step8_post_processing']['edge_preserving']['anisotropic_kappa'] if cfg else 50.0
# è‰²å½©ä¸€è‡´æ€§æ ¡æ­£
USE_COLOR_CORRECTION = cfg['step8_post_processing']['color_correction']['enable'] if cfg else True
COLOR_CORRECTION_METHOD = cfg['step8_post_processing']['color_correction']['method'] if cfg else "histogram"
HISTOGRAM_MATCH_PERCENTILE = cfg['step8_post_processing']['color_correction']['histogram_match_percentile'] if cfg else 5.0
COLOR_TRANSFER_PRESERVE_LUMINANCE = cfg['step8_post_processing']['color_correction']['transfer_preserve_luminance'] if cfg else True

# æ£€æµ‹GPUå¯ç”¨æ€§å¹¶è®¾ç½®
if USE_GPU and GPU_AVAILABLE:
    try:
        device = cp.cuda.Device(GPU_DEVICE_ID)
        device.use()
        USE_GPU = True
        print(f"\nğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨")
        # è·å–GPUåç§°ï¼ˆå…¼å®¹ä¸åŒCuPyç‰ˆæœ¬ï¼‰
        try:
            gpu_name = device.attributes.get('Name', b'Unknown GPU')
            if isinstance(gpu_name, bytes):
                gpu_name = gpu_name.decode()
            print(f"  - GPUè®¾å¤‡: {gpu_name}")
        except:
            print(f"  - GPUè®¾å¤‡: Device {GPU_DEVICE_ID}")
        # è·å–æ˜¾å­˜ä¿¡æ¯
        try:
            mem_total = device.mem_info[1] / 10243
            print(f"  - æ˜¾å­˜: {mem_total:.1f} GB")
        except:
            print(f"  - æ˜¾å­˜: å¯ç”¨")
    except Exception as e:
        print(f"\nâš ï¸  GPUåˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ°CPUæ¨¡å¼: {e}")
        USE_GPU = False
elif USE_GPU and not GPU_AVAILABLE:
    print(f"\nâš ï¸  CuPyæœªå®‰è£…æˆ–GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    print(f"     å®‰è£…å‘½ä»¤: pip install cupy-cuda12x")
    USE_GPU = False
else:
    print(f"\nğŸ’» ä½¿ç”¨CPUæ¨¡å¼")

print(f"\né…ç½®:")
print(f"  - è®¡ç®—è®¾å¤‡: {'GPU' if USE_GPU else 'CPU'}")
print(f"  - é‡‡æ ·ç‡: æ¯{FRAME_SAMPLE_RATE}å¸§")
print(f"  - æœ€å¤§å¸§æ•°: {MAX_IMAGES}")
print(f"  - å›ºå®šæ‘„åƒå¤´é«˜åº¦: {'å¼€å¯' if FIX_CAMERA_HEIGHT else 'å…³é—­'}")
if FIX_CAMERA_HEIGHT and FIXED_HEIGHT is not None:
    print(f"    â””â”€ å›ºå®šé«˜åº¦å€¼: {FIXED_HEIGHT:.3f}m")
print(f"  - å¼ºåˆ¶ç›¸æœºæ°´å¹³: {'å¼€å¯' if FORCE_CAMERA_HORIZONTAL else 'å…³é—­'}")
print(f"  - æ·±åº¦ä¸€è‡´æ€§: {'å¼€å¯' if USE_DEPTH_CONSISTENCY else 'å…³é—­'}")
print(f"  - è§†è§’åŠ æƒ: {'å¼€å¯' if USE_ANGLE_WEIGHTING else 'å…³é—­'}")
print(f"  - æ›å…‰è¡¥å¿: {'å¼€å¯' if USE_EXPOSURE_COMP else 'å…³é—­'}")
print(f"  - è½¦è¾†æ£€æµ‹ï¼ˆå››æ¨¡æ€ï¼‰: {'âœ“ å¼€å¯' if USE_VEHICLE_DETECTION else 'å…³é—­'}")
if USE_VEHICLE_DETECTION:
    enabled_cues = []
    if USE_GROUND_NORMAL:
        enabled_cues.append(f"æ³•å‘(>{GROUND_NORMAL_THRESHOLD:.2f})")
    if USE_HEIGHT_FILTER:
        enabled_cues.append(f"é«˜åº¦({VEHICLE_HEIGHT_MIN}-{VEHICLE_HEIGHT_MAX}m)")
    if USE_DEPTH_DISCONTINUITY:
        enabled_cues.append(f"æ¢¯åº¦(>{DEPTH_GRADIENT_THRESHOLD}m/px)")
    if USE_TSDF_DEPTH_CONSISTENCY:
        enabled_cues.append(f"TSDFæ·±åº¦(>{DEPTH_DIFF_THRESHOLD}m)")
    print(f"    â””â”€ å¯ç”¨çº¿ç´¢: {' + '.join(enabled_cues)}")
    print(f"    â””â”€ èåˆæ–¹å¼: {'AND (æ‰€æœ‰æ»¡è¶³)' if REQUIRE_ALL_CUES else 'OR (ä»»æ„æ»¡è¶³)'}")
print(f"  - å›¾åƒè´¨é‡è¿‡æ»¤: {'âœ“ å¼€å¯ (ç¬¬1æ­¥ä¼˜åŒ–)' if USE_IMAGE_QUALITY_FILTER else 'å…³é—­'}")
if USE_IMAGE_QUALITY_FILTER:
    print(f"    â””â”€ è´¨é‡é˜ˆå€¼: {IMAGE_QUALITY_THRESHOLD:.0f}")
    print(f"    â””â”€ æ¸…æ™°åº¦é˜ˆå€¼: {SHARPNESS_THRESHOLD:.0f}")
    print(f"    â””â”€ æœ€å¤§è¿‡æ›: {MAX_OVEREXPOSURE*100:.0f}%")
    print(f"    â””â”€ æœ€å¤§æ¬ æ›: {MAX_UNDEREXPOSURE*100:.0f}%")
print(f"  - å›¾åƒé¢„å¤„ç†å¢å¼º: {'âœ“ å¼€å¯ (ç¬¬2æ­¥ä¼˜åŒ–)' if USE_IMAGE_ENHANCEMENT else 'å…³é—­'}")
if USE_IMAGE_ENHANCEMENT:
    enhancement_methods = []
    if USE_BILATERAL_FILTER:
        enhancement_methods.append(f"åŒè¾¹æ»¤æ³¢(d={BILATERAL_D})")
    if USE_CLAHE:
        enhancement_methods.append(f"CLAHE(clip={CLAHE_CLIP_LIMIT})")
    if USE_UNSHARP_MASK:
        enhancement_methods.append(f"éé”åŒ–(r={UNSHARP_RADIUS}, a={UNSHARP_AMOUNT})")
    if enhancement_methods:
        print(f"    â””â”€ {' + '.join(enhancement_methods)}")
print(f"  - åŒä¸‰æ¬¡æ’å€¼: {'âœ“ å¼€å¯ (ç¬¬3æ­¥ä¼˜åŒ–, a={BICUBIC_A})' if USE_BICUBIC_INTERPOLATION else 'å…³é—­ (ä½¿ç”¨åŒçº¿æ€§)'}")

# ç¬¬4æ­¥ä¼˜åŒ–é…ç½®æ˜¾ç¤º
if USE_SMART_VIEW_WEIGHTING:
    print(f"  - æ™ºèƒ½è§†è§’åŠ æƒ: âœ“ å¼€å¯ (ç¬¬4æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ æƒé‡é…ç½®: è§†è§’{VIEW_ANGLE_WEIGHT:.1f} + è·ç¦»{DISTANCE_WEIGHT:.1f} + è´¨é‡{IMAGE_QUALITY_WEIGHT:.1f}")
    print(f"    â””â”€ æœ€å¤§è§†è§’: {MAX_VIEW_ANGLE_DEG:.0f}Â°, è·ç¦»è¡°å‡: {DISTANCE_FALLOFF:.1f}, æœ€å°æƒé‡: {MIN_EFFECTIVE_WEIGHT:.2f}")
elif USE_ANGLE_WEIGHTING:
    print(f"  - ä¼ ç»Ÿè§†è§’åŠ æƒ: å¼€å¯ (é˜ˆå€¼: {ANGLE_THRESHOLD_DEG}Â°)")
else:
    print(f"  - è§†è§’åŠ æƒ: å…³é—­")

# ç¬¬5æ­¥ä¼˜åŒ–é…ç½®æ˜¾ç¤º
if USE_SEAM_SMOOTHING:
    print(f"  - æ¥ç¼å¹³æ»‘: âœ“ å¼€å¯ (ç¬¬5æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ æ–¹å·®é˜ˆå€¼: {VARIANCE_THRESHOLD:.3f}, å¹³æ»‘å¼ºåº¦: {SMOOTHING_STRENGTH:.1f}, é‚»åŸŸ: {SEAM_K_NEIGHBORS}é¡¶ç‚¹")
else:
    print(f"  - æ¥ç¼å¹³æ»‘: å…³é—­")

# ç¬¬6æ­¥ä¼˜åŒ–é…ç½®æ˜¾ç¤º
if USE_LAB_COLOR_SPACE:
    print(f"  - LABè‰²å½©ç©ºé—´: âœ“ å¼€å¯ (ç¬¬6æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ Lé€šé“æƒé‡: {LAB_L_WEIGHT}, å½’ä¸€åŒ–: {'æ˜¯' if LAB_NORMALIZE_L else 'å¦'}, è£å‰ªç™¾åˆ†ä½: {LAB_L_CLIP_PERCENTILE:.1f}%")
else:
    print(f"  - LABè‰²å½©ç©ºé—´: å…³é—­ (RGBç©ºé—´)")

# ç¬¬7æ­¥ä¼˜åŒ–é…ç½®æ˜¾ç¤º
if USE_SUBPIXEL_PRECISION:
    print(f"  - äºšåƒç´ ç²¾åº¦æŠ•å½±: âœ“ å¼€å¯ (ç¬¬7æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ æŠ•å½±ç²¾åº¦: {'float64' if USE_FLOAT64_PROJECTION else 'float32'}, æƒé‡æ¨¡å¼: {SUBPIXEL_WEIGHT_MODE}")
    print(f"    â””â”€ ä¿ç•™äºšåƒç´ æƒé‡: {'æ˜¯' if PRESERVE_SUBPIXEL_WEIGHT else 'å¦'}, æ•°å€¼é˜ˆå€¼: {PROJECTION_EPSILON:.0e}")
else:
    print(f"  - äºšåƒç´ ç²¾åº¦æŠ•å½±: å…³é—­ (æ ‡å‡†intæŠ•å½±)")

# ============================================================================
# å›¾åƒè´¨é‡è¯„ä¼°å‡½æ•°
# ============================================================================
def assess_image_quality(rgb_img):
    """
    è¯„ä¼°å›¾åƒè´¨é‡ï¼šæ¸…æ™°åº¦å’Œæ›å…‰
    
    å‚æ•°:
        rgb_img: RGBå›¾åƒï¼Œå–å€¼èŒƒå›´0-1ï¼Œå½¢çŠ¶(H, W, 3)
    
    è¿”å›:
        quality_score: ç»¼åˆè´¨é‡åˆ†æ•°
        sharpness: æ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
        overexposed: è¿‡æ›åƒç´ æ¯”ä¾‹
        underexposed: æ¬ æ›åƒç´ æ¯”ä¾‹
        contrast: å¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
    """
    # è½¬æ¢ä¸ºç°åº¦å›¾ç”¨äºåˆ†æ
    gray = cv2.cvtColor((rgb_img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    
    # 1. æ‹‰æ™®æ‹‰æ–¯æ–¹å·® - æ£€æµ‹æ¨¡ç³Šï¼ˆæ¸…æ™°åº¦æŒ‡æ ‡ï¼‰
    # æ¨¡ç³Šå›¾åƒçš„æ‹‰æ™®æ‹‰æ–¯æ–¹å·®è¾ƒä½
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    sharpness = laplacian.var()
    
    # 2. ç›´æ–¹å›¾åˆ†æ - æ£€æµ‹æ›å…‰é—®é¢˜
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    total_pixels = hist.sum()
    
    # è¿‡æ›ï¼šç°åº¦å€¼>240çš„åƒç´ æ¯”ä¾‹
    overexposed = np.sum(hist[240:]) / total_pixels
    
    # æ¬ æ›ï¼šç°åº¦å€¼<15çš„åƒç´ æ¯”ä¾‹
    underexposed = np.sum(hist[:15]) / total_pixels
    
    # 3. å¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
    contrast = gray.std()
    
    # 4. è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
    # å…¬å¼ï¼šæ¸…æ™°åº¦ Ã— (1 - æ›å…‰é—®é¢˜) Ã— (å¯¹æ¯”åº¦å› å­)
    exposure_penalty = 1.0 - overexposed - underexposed
    contrast_factor = min(contrast / 50.0, 1.0)  # æ ‡å‡†åŒ–åˆ°0-1
    
    quality_score = sharpness * exposure_penalty * contrast_factor
    
    return quality_score, sharpness, overexposed, underexposed, contrast

# ============================================================================
# å›¾åƒå¢å¼ºå‡½æ•°ï¼ˆç¬¬2æ­¥ä¼˜åŒ–ï¼‰
# ============================================================================
def apply_unsharp_mask(image, radius=2.0, amount=1.5):
    """
    éé”åŒ–æ©è”½ï¼ˆUnsharp Maskingï¼‰- å¢å¼ºå›¾åƒç»†èŠ‚å’Œè¾¹ç¼˜
    
    åŸç†ï¼šåŸå§‹å›¾åƒ + (åŸå§‹å›¾åƒ - æ¨¡ç³Šå›¾åƒ) Ã— å¼ºåº¦
    
    å‚æ•°:
        image: RGBå›¾åƒï¼Œå–å€¼0-1ï¼Œå½¢çŠ¶(H, W, 3)
        radius: é«˜æ–¯æ¨¡ç³ŠåŠå¾„ï¼ˆè¶Šå¤§å¢å¼ºè¶Šå¼ºï¼Œå»ºè®®1.0-3.0ï¼‰
        amount: é”åŒ–å¼ºåº¦ï¼ˆè¶Šå¤§è¶Šé”åˆ©ï¼Œå»ºè®®1.0-2.0ï¼‰
    
    è¿”å›:
        å¢å¼ºåçš„å›¾åƒï¼Œå–å€¼0-1
    """
    # è½¬æ¢åˆ°uint8è¿›è¡Œå¤„ç†
    img_uint8 = (image * 255).astype(np.uint8)
    
    # åˆ›å»ºé«˜æ–¯æ¨¡ç³Šç‰ˆæœ¬
    kernel_size = int(2 * np.ceil(2 * radius) + 1)  # ä¿è¯å¥‡æ•°
    blurred = cv2.GaussianBlur(img_uint8, (kernel_size, kernel_size), radius)
    
    # è®¡ç®—é”åŒ–æ©æ¨¡ï¼šåŸå›¾ - æ¨¡ç³Šå›¾
    mask = cv2.subtract(img_uint8, blurred)
    
    # åº”ç”¨é”åŒ–ï¼šåŸå›¾ + æ©æ¨¡ Ã— å¼ºåº¦
    sharpened = cv2.addWeighted(img_uint8, 1.0, mask, amount, 0)
    
    # è½¬æ¢å›0-1èŒƒå›´
    return sharpened.astype(np.float32) / 255.0


def apply_bilateral_filter(image, d=5, sigma_color=75, sigma_space=75):
    """
    åŒè¾¹æ»¤æ³¢ - å»å™ªåŒæ—¶ä¿æŒè¾¹ç¼˜
    
    åŸç†ï¼šåŒæ—¶è€ƒè™‘ç©ºé—´è·ç¦»å’Œé¢œè‰²ç›¸ä¼¼åº¦çš„åŠ æƒå¹³å‡
    
    å‚æ•°:
        image: RGBå›¾åƒï¼Œå–å€¼0-1ï¼Œå½¢çŠ¶(H, W, 3)
        d: æ»¤æ³¢ç›´å¾„ï¼ˆå»ºè®®5-9ï¼‰
        sigma_color: é¢œè‰²ç©ºé—´æ ‡å‡†å·®ï¼ˆå»ºè®®50-100ï¼Œè¶Šå¤§é¢œè‰²å·®å¼‚è¶Šè¢«å¿½ç•¥ï¼‰
        sigma_space: åæ ‡ç©ºé—´æ ‡å‡†å·®ï¼ˆå»ºè®®50-100ï¼Œè¶Šå¤§åƒç´ å½±å“èŒƒå›´è¶Šå¹¿ï¼‰
    
    è¿”å›:
        å»å™ªåçš„å›¾åƒï¼Œå–å€¼0-1
    """
    # è½¬æ¢åˆ°uint8
    img_uint8 = (image * 255).astype(np.uint8)
    
    # åº”ç”¨åŒè¾¹æ»¤æ³¢
    filtered = cv2.bilateralFilter(img_uint8, d, sigma_color, sigma_space)
    
    # è½¬æ¢å›0-1èŒƒå›´
    return filtered.astype(np.float32) / 255.0


def apply_clahe(image, clip_limit=2.0, tile_size=8):
    """
    CLAHEï¼ˆå¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰- å¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦
    
    åŸç†ï¼šåœ¨å°åŒºåŸŸå†…è¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ŒåŒæ—¶é™åˆ¶å¯¹æ¯”åº¦å¢å¼º
    
    å‚æ•°:
        image: RGBå›¾åƒï¼Œå–å€¼0-1ï¼Œå½¢çŠ¶(H, W, 3)
        clip_limit: å¯¹æ¯”åº¦é™åˆ¶ï¼ˆ1.0-4.0ï¼Œè¶Šå¤§å¯¹æ¯”åº¦è¶Šå¼ºï¼‰
        tile_size: ç½‘æ ¼å¤§å°ï¼ˆ8-16ï¼Œè¶Šå°å±€éƒ¨å¯¹æ¯”åº¦è¶Šå¼ºï¼‰
    
    è¿”å›:
        å¢å¼ºåçš„å›¾åƒï¼Œå–å€¼0-1
    """
    # è½¬æ¢åˆ°uint8
    img_uint8 = (image * 255).astype(np.uint8)
    
    # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´ï¼ˆåªå¯¹äº®åº¦é€šé“å¢å¼ºï¼‰
    lab = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2LAB)
    l_channel, a_channel, b_channel = cv2.split(lab)
    
    # åˆ›å»ºCLAHEå¯¹è±¡å¹¶åº”ç”¨åˆ°Lé€šé“
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_size, tile_size))
    l_enhanced = clahe.apply(l_channel)
    
    # åˆå¹¶é€šé“
    lab_enhanced = cv2.merge([l_enhanced, a_channel, b_channel])
    
    # è½¬æ¢å›RGB
    rgb_enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)
    
    # è½¬æ¢å›0-1èŒƒå›´
    return rgb_enhanced.astype(np.float32) / 255.0


def enhance_image(image):
    """
    ç»¼åˆå›¾åƒå¢å¼ºå‡½æ•° - æ•´åˆå¤šç§å¢å¼ºæŠ€æœ¯
    
    å¤„ç†æµç¨‹ï¼š
    1. åŒè¾¹æ»¤æ³¢å»å™ªï¼ˆå¯é€‰ï¼‰
    2. CLAHEå¯¹æ¯”åº¦å¢å¼ºï¼ˆå¯é€‰ï¼‰
    3. éé”åŒ–æ©è”½é”åŒ–ï¼ˆå¯é€‰ï¼‰
    
    å‚æ•°:
        image: RGBå›¾åƒï¼Œå–å€¼0-1ï¼Œå½¢çŠ¶(H, W, 3)
    
    è¿”å›:
        å¢å¼ºåçš„å›¾åƒï¼Œå–å€¼0-1
    """
    if not USE_IMAGE_ENHANCEMENT:
        return image
    
    enhanced = image.copy()
    
    # ç¬¬1æ­¥ï¼šå»å™ªï¼ˆåŒè¾¹æ»¤æ³¢ï¼‰ - å…ˆå»å™ªå†å¢å¼ºæ•ˆæœæ›´å¥½
    if USE_BILATERAL_FILTER:
        enhanced = apply_bilateral_filter(
            enhanced, 
            d=BILATERAL_D,
            sigma_color=BILATERAL_SIGMA_COLOR,
            sigma_space=BILATERAL_SIGMA_SPACE
        )
    
    # ç¬¬2æ­¥ï¼šå¯¹æ¯”åº¦å¢å¼ºï¼ˆCLAHEï¼‰
    if USE_CLAHE:
        enhanced = apply_clahe(
            enhanced,
            clip_limit=CLAHE_CLIP_LIMIT,
            tile_size=CLAHE_TILE_SIZE
        )
    
    # ç¬¬3æ­¥ï¼šé”åŒ–ï¼ˆéé”åŒ–æ©è”½ï¼‰
    if USE_UNSHARP_MASK:
        enhanced = apply_unsharp_mask(
            enhanced,
            radius=UNSHARP_RADIUS,
            amount=UNSHARP_AMOUNT
        )
    
    # ç¡®ä¿å€¼åŸŸåœ¨0-1
    enhanced = np.clip(enhanced, 0.0, 1.0)
    
    return enhanced

# ============================================================================
# ç¬¬7æ­¥ä¼˜åŒ–ï¼šäºšåƒç´ ç²¾åº¦æŠ•å½±å‡½æ•°
# ============================================================================
def project_vertices_subpixel(vertices_cam, K, H, W, use_float64=True):
    """
    é«˜ç²¾åº¦æŠ•å½±3Dç‚¹åˆ°2Dåƒç´ åæ ‡ï¼ˆäºšåƒç´ çº§ç²¾åº¦ï¼‰
    
    å‚æ•°:
        vertices_cam: ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dç‚¹ (N, 3)ï¼Œfloat32/float64
        K: ç›¸æœºå†…å‚çŸ©é˜µ (3, 3)
        H, W: å›¾åƒé«˜åº¦å’Œå®½åº¦
        use_float64: æ˜¯å¦ä½¿ç”¨float64æé«˜ç²¾åº¦
    
    è¿”å›:
        u_f, v_f: æµ®ç‚¹åƒç´ åæ ‡ (N,)ï¼Œä¿ç•™å®Œæ•´äºšåƒç´ ç²¾åº¦
    """
    if use_float64:
        # è½¬æ¢ä¸ºfloat64æé«˜ç²¾åº¦
        vertices_cam = vertices_cam.astype(np.float64)
        K = K.astype(np.float64)
    
    # é€è§†æŠ•å½±ï¼ˆä¿æŒé«˜ç²¾åº¦ï¼‰
    points_2d = K @ vertices_cam.T  # (3, N)
    
    # é˜²æ­¢é™¤é›¶ï¼ˆä½¿ç”¨æ›´å°çš„epsilonæé«˜ç²¾åº¦ï¼‰
    depths = points_2d[2, :]
    depths = np.where(np.abs(depths) < PROJECTION_EPSILON, PROJECTION_EPSILON, depths)
    
    # å½’ä¸€åŒ–åˆ°åƒç´ åæ ‡ï¼ˆå®Œæ•´æµ®ç‚¹ç²¾åº¦ï¼‰
    u_f = points_2d[0, :] / depths
    v_f = points_2d[1, :] / depths
    
    # Yè½´ç¿»è½¬ï¼ˆOpenCVåæ ‡ç³»ï¼‰
    v_f = H - 1.0 - v_f
    
    return u_f, v_f


def project_vertices_subpixel_gpu(vertices_cam_gpu, K_gpu, H, W, use_float64=True):
    """
    é«˜ç²¾åº¦æŠ•å½±3Dç‚¹åˆ°2Dåƒç´ åæ ‡ï¼ˆGPUç‰ˆæœ¬ï¼Œäºšåƒç´ çº§ç²¾åº¦ï¼‰
    
    å‚æ•°:
        vertices_cam_gpu: ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dç‚¹ (N, 3)ï¼ŒCuPyæ•°ç»„
        K_gpu: ç›¸æœºå†…å‚çŸ©é˜µ (3, 3)ï¼ŒCuPyæ•°ç»„
        H, W: å›¾åƒé«˜åº¦å’Œå®½åº¦
        use_float64: æ˜¯å¦ä½¿ç”¨float64æé«˜ç²¾åº¦
    
    è¿”å›:
        u_f_gpu, v_f_gpu: æµ®ç‚¹åƒç´ åæ ‡ (N,)ï¼ŒCuPyæ•°ç»„ï¼Œä¿ç•™å®Œæ•´äºšåƒç´ ç²¾åº¦
    """
    xp = cp
    if use_float64:
        # è½¬æ¢ä¸ºfloat64æé«˜ç²¾åº¦
        vertices_cam_gpu = vertices_cam_gpu.astype(xp.float64)
        K_gpu = K_gpu.astype(xp.float64)
    
    # é€è§†æŠ•å½±ï¼ˆä¿æŒé«˜ç²¾åº¦ï¼‰
    points_2d_gpu = K_gpu @ vertices_cam_gpu.T  # (3, N)
    
    # é˜²æ­¢é™¤é›¶
    depths = points_2d_gpu[2, :]
    epsilon = xp.float64(PROJECTION_EPSILON) if use_float64 else xp.float32(PROJECTION_EPSILON)
    depths = xp.where(xp.abs(depths) < epsilon, epsilon, depths)
    
    # å½’ä¸€åŒ–åˆ°åƒç´ åæ ‡ï¼ˆå®Œæ•´æµ®ç‚¹ç²¾åº¦ï¼‰
    u_f_gpu = points_2d_gpu[0, :] / depths
    v_f_gpu = points_2d_gpu[1, :] / depths
    
    # Yè½´ç¿»è½¬ï¼ˆOpenCVåæ ‡ç³»ï¼‰
    v_f_gpu = H - 1.0 - v_f_gpu
    
    # è½¬å›float32ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if use_float64:
        u_f_gpu = u_f_gpu.astype(xp.float32)
        v_f_gpu = v_f_gpu.astype(xp.float32)
    
    return u_f_gpu, v_f_gpu


def compute_subpixel_weights(u_f, v_f, mode="bilinear"):
    """
    è®¡ç®—äºšåƒç´ ä½ç½®çš„æ’å€¼æƒé‡ï¼ˆä¸è¿›è¡Œé‡åŒ–ï¼‰
    
    å‚æ•°:
        u_f, v_f: æµ®ç‚¹åƒç´ åæ ‡ (N,)
        mode: æ’å€¼æ¨¡å¼ "bilinear" æˆ– "bicubic"
    
    è¿”å›:
        weights: äºšåƒç´ æƒé‡ä¿¡æ¯å­—å…¸
            - "u_int", "v_int": æ•´æ•°åæ ‡
            - "u_frac", "v_frac": å°æ•°éƒ¨åˆ†ï¼ˆäºšåƒç´ åç§»ï¼‰
            - "mode": æ’å€¼æ¨¡å¼
    """
    # æ•´æ•°éƒ¨åˆ†å’Œå°æ•°éƒ¨åˆ†ï¼ˆä¿ç•™å®Œæ•´ç²¾åº¦ï¼‰
    u_int = np.floor(u_f).astype(np.int32)
    v_int = np.floor(v_f).astype(np.int32)
    u_frac = u_f - u_int  # äºšåƒç´ åç§» [0, 1)
    v_frac = v_f - v_int  # äºšåƒç´ åç§» [0, 1)
    
    weights = {
        "u_int": u_int,
        "v_int": v_int,
        "u_frac": u_frac,  # å…³é”®ï¼šä¿ç•™å°æ•°ç²¾åº¦
        "v_frac": v_frac,
        "mode": mode
    }
    
    return weights


def sample_with_subpixel_weights(img, weights, H, W):
    """
    ä½¿ç”¨äºšåƒç´ æƒé‡è¿›è¡Œå›¾åƒé‡‡æ ·
    
    å‚æ•°:
        img: è¾“å…¥å›¾åƒ (H, W, C)
        weights: compute_subpixel_weightsè¿”å›çš„æƒé‡å­—å…¸
        H, W: å›¾åƒå°ºå¯¸
    
    è¿”å›:
        colors: é‡‡æ ·é¢œè‰² (N, C)
    """
    u_int = weights["u_int"]
    v_int = weights["v_int"]
    u_frac = weights["u_frac"]
    v_frac = weights["v_frac"]
    mode = weights["mode"]
    
    if mode == "bilinear":
        # åŒçº¿æ€§æ’å€¼ï¼ˆ4ä¸ªé‚»åŸŸåƒç´ ï¼‰
        u0, v0 = u_int, v_int
        u1 = np.minimum(u0 + 1, W - 1)
        v1 = np.minimum(v0 + 1, H - 1)
        u0 = np.maximum(u0, 0)
        v0 = np.maximum(v0, 0)
        
        # 4ä¸ªè§’ç‚¹
        c00 = img[v0, u0]
        c10 = img[v0, u1]
        c01 = img[v1, u0]
        c11 = img[v1, u1]
        
        # åŒçº¿æ€§æ’å€¼ï¼ˆä¿ç•™äºšåƒç´ æƒé‡ç²¾åº¦ï¼‰
        wu = u_frac[:, np.newaxis]  # (N, 1)
        wv = v_frac[:, np.newaxis]  # (N, 1)
        
        colors = (c00 * (1 - wu) * (1 - wv) +
                  c10 * wu * (1 - wv) +
                  c01 * (1 - wu) * wv +
                  c11 * wu * wv)
        
    elif mode == "bicubic":
        # åŒä¸‰æ¬¡æ’å€¼ï¼ˆ16ä¸ªé‚»åŸŸåƒç´ ï¼‰- å¤ç”¨ç°æœ‰å‡½æ•°
        colors = bicubic_interpolate(img, u_int + u_frac, v_int + v_frac, a=-0.5)
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ’å€¼æ¨¡å¼: {mode}")
    
    return colors


# ============================================================================
# ç¬¬8æ­¥ä¼˜åŒ–ï¼šçº¹ç†åå¤„ç†å‡½æ•°
# ============================================================================

def detect_outliers_statistical(colors, weights, threshold=3.0):
    """
    ç»Ÿè®¡å­¦æ–¹æ³•æ£€æµ‹é¢œè‰²å¼‚å¸¸å€¼ï¼ˆåŸºäºZ-scoreï¼‰
    
    å‚æ•°:
        colors: é¡¶ç‚¹é¢œè‰² (N, 3) float32/float64ï¼ŒèŒƒå›´0-1
        weights: é¡¶ç‚¹æƒé‡ (N,)ï¼Œç”¨äºåŠ æƒç»Ÿè®¡
        threshold: Z-scoreé˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰ï¼Œé»˜è®¤3.0
    
    è¿”å›:
        outlier_mask: å¼‚å¸¸å€¼æ©ç  (N,) boolï¼ŒTrueè¡¨ç¤ºå¼‚å¸¸å€¼
    """
    if len(colors) == 0:
        return np.zeros(len(colors), dtype=bool)
    
    # åŠ æƒè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ¯ä¸ªé€šé“ç‹¬ç«‹ï¼‰
    valid_mask = weights > 0
    if not valid_mask.any():
        return np.zeros(len(colors), dtype=bool)
    
    weights_norm = weights[valid_mask] / weights[valid_mask].sum()
    
    # é€é€šé“è®¡ç®—åŠ æƒç»Ÿè®¡é‡
    outlier_mask = np.zeros(len(colors), dtype=bool)
    
    for c in range(colors.shape[1]):
        channel = colors[valid_mask, c]
        mean_c = np.average(channel, weights=weights_norm)
        var_c = np.average((channel - mean_c)**2, weights=weights_norm)
        std_c = np.sqrt(var_c) + 1e-8  # é˜²æ­¢é™¤é›¶
        
        # Z-scoreæ£€æµ‹
        z_scores = np.abs((colors[:, c] - mean_c) / std_c)
        outlier_mask |= (z_scores > threshold)
    
    return outlier_mask


def detect_outliers_local(vertex_colors, vertex_positions, weights, 
                          k_neighbors=8, threshold=2.5):
    """
    å±€éƒ¨é‚»åŸŸæ–¹æ³•æ£€æµ‹é¢œè‰²å¼‚å¸¸å€¼
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        k_neighbors: Kè¿‘é‚»æ•°é‡
        threshold: å±€éƒ¨å¼‚å¸¸é˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰
    
    è¿”å›:
        outlier_mask: å¼‚å¸¸å€¼æ©ç  (N,) bool
    """
    from sklearn.neighbors import NearestNeighbors
    
    if len(vertex_colors) == 0 or len(vertex_colors) < k_neighbors:
        return np.zeros(len(vertex_colors), dtype=bool)
    
    valid_mask = weights > 0
    if valid_mask.sum() < k_neighbors:
        return np.zeros(len(vertex_colors), dtype=bool)
    
    # æ„å»ºKNNç´¢å¼•ï¼ˆåªè€ƒè™‘æœ‰æƒé‡çš„é¡¶ç‚¹ï¼‰
    valid_positions = vertex_positions[valid_mask]
    valid_colors = vertex_colors[valid_mask]
    
    # é¿å…k_neighborsè¶…è¿‡æœ‰æ•ˆé¡¶ç‚¹æ•°
    k = min(k_neighbors, len(valid_positions) - 1)
    
    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(valid_positions)
    distances, indices = nbrs.kneighbors(valid_positions)
    
    # è®¡ç®—æ¯ä¸ªé¡¶ç‚¹ä¸å…¶é‚»åŸŸçš„é¢œè‰²åå·®
    outlier_mask_local = np.zeros(valid_mask.sum(), dtype=bool)
    
    for i in range(len(valid_colors)):
        # é‚»åŸŸç´¢å¼•ï¼ˆæ’é™¤è‡ªå·±ï¼‰
        neighbor_idx = indices[i, 1:]
        neighbor_colors = valid_colors[neighbor_idx]
        
        # è®¡ç®—é‚»åŸŸé¢œè‰²å‡å€¼å’Œæ ‡å‡†å·®
        mean_color = neighbor_colors.mean(axis=0)
        std_color = neighbor_colors.std(axis=0) + 1e-8
        
        # è®¡ç®—å½“å‰é¡¶ç‚¹ä¸é‚»åŸŸçš„å·®å¼‚
        color_diff = np.abs(valid_colors[i] - mean_color) / std_color
        
        # ä»»ä¸€é€šé“è¶…è¿‡é˜ˆå€¼åˆ™æ ‡è®°ä¸ºå¼‚å¸¸
        if (color_diff > threshold).any():
            outlier_mask_local[i] = True
    
    # å°†å±€éƒ¨æ©ç æ˜ å°„å›å…¨å±€
    outlier_mask = np.zeros(len(vertex_colors), dtype=bool)
    outlier_mask[valid_mask] = outlier_mask_local
    
    return outlier_mask


def detect_outliers(vertex_colors, vertex_positions, weights, 
                    method="both", zscore_threshold=3.0, 
                    local_k=8, local_threshold=2.5):
    """
    ç»¼åˆå¼‚å¸¸å€¼æ£€æµ‹ï¼ˆç»Ÿè®¡å­¦ + å±€éƒ¨é‚»åŸŸï¼‰
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        method: æ£€æµ‹æ–¹æ³• "statistical"/"local"/"both"
        zscore_threshold: ç»Ÿè®¡å­¦Z-scoreé˜ˆå€¼
        local_k: å±€éƒ¨é‚»åŸŸKè¿‘é‚»æ•°é‡
        local_threshold: å±€éƒ¨å¼‚å¸¸é˜ˆå€¼
    
    è¿”å›:
        outlier_mask: å¼‚å¸¸å€¼æ©ç  (N,) bool
        outlier_count: æ£€æµ‹åˆ°çš„å¼‚å¸¸å€¼æ•°é‡
    """
    if method == "statistical":
        outlier_mask = detect_outliers_statistical(vertex_colors, weights, zscore_threshold)
    elif method == "local":
        outlier_mask = detect_outliers_local(vertex_colors, vertex_positions, weights, 
                                             local_k, local_threshold)
    elif method == "both":
        # ä¸¤ç§æ–¹æ³•çš„å¹¶é›†
        mask1 = detect_outliers_statistical(vertex_colors, weights, zscore_threshold)
        mask2 = detect_outliers_local(vertex_colors, vertex_positions, weights, 
                                      local_k, local_threshold)
        outlier_mask = mask1 | mask2
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ£€æµ‹æ–¹æ³•: {method}")
    
    outlier_count = outlier_mask.sum()
    return outlier_mask, outlier_count


def bilateral_filter_texture(vertex_colors, vertex_positions, weights,
                             sigma_spatial=5.0, sigma_color=0.1, k_neighbors=16):
    """
    åŒè¾¹æ»¤æ³¢è¿›è¡Œè¾¹ç¼˜ä¿æŒå¹³æ»‘
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3) èŒƒå›´0-1
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        sigma_spatial: ç©ºé—´æ ‡å‡†å·®ï¼ˆç±³ï¼‰
        sigma_color: é¢œè‰²æ ‡å‡†å·®ï¼ˆ0-1èŒƒå›´ï¼‰
        k_neighbors: Kè¿‘é‚»æ•°é‡
    
    è¿”å›:
        filtered_colors: æ»¤æ³¢åçš„é¢œè‰² (N, 3)
    """
    from sklearn.neighbors import NearestNeighbors
    
    if len(vertex_colors) == 0:
        return vertex_colors.copy()
    
    valid_mask = weights > 0
    if valid_mask.sum() < k_neighbors:
        return vertex_colors.copy()
    
    filtered_colors = vertex_colors.copy()
    
    # æ„å»ºKNNç´¢å¼•
    valid_positions = vertex_positions[valid_mask]
    valid_colors = vertex_colors[valid_mask]
    
    k = min(k_neighbors, len(valid_positions) - 1)
    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(valid_positions)
    distances, indices = nbrs.kneighbors(valid_positions)
    
    # å¯¹æ¯ä¸ªæœ‰æ•ˆé¡¶ç‚¹è¿›è¡ŒåŒè¾¹æ»¤æ³¢
    filtered_valid = np.zeros_like(valid_colors)
    
    for i in range(len(valid_colors)):
        neighbor_idx = indices[i, 1:]
        neighbor_pos = valid_positions[neighbor_idx]
        neighbor_colors = valid_colors[neighbor_idx]
        spatial_dist = distances[i, 1:]
        
        # è®¡ç®—ç©ºé—´æƒé‡ï¼ˆé«˜æ–¯ï¼‰
        w_spatial = np.exp(-(spatial_dist2) / (2 * sigma_spatial2))
        
        # è®¡ç®—é¢œè‰²æƒé‡ï¼ˆé«˜æ–¯ï¼‰
        color_dist = np.linalg.norm(neighbor_colors - valid_colors[i], axis=1)
        w_color = np.exp(-(color_dist2) / (2 * sigma_color2))
        
        # ç»¼åˆæƒé‡
        w_total = w_spatial * w_color
        w_total = w_total / (w_total.sum() + 1e-8)
        
        # åŠ æƒå¹³å‡
        filtered_valid[i] = (neighbor_colors * w_total[:, np.newaxis]).sum(axis=0)
    
    filtered_colors[valid_mask] = filtered_valid
    return filtered_colors


def anisotropic_diffusion_texture(vertex_colors, vertex_positions, weights,
                                  iterations=10, kappa=50.0, gamma=0.1):
    """
    å„å‘å¼‚æ€§æ‰©æ•£è¿›è¡Œè¾¹ç¼˜ä¿æŒå¹³æ»‘
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        iterations: è¿­ä»£æ¬¡æ•°
        kappa: è¾¹ç¼˜æ•æ„Ÿåº¦å‚æ•°ï¼ˆé¢œè‰²æ¢¯åº¦é˜ˆå€¼ï¼Œ0-1ï¼‰
        gamma: æ‰©æ•£æ­¥é•¿ï¼ˆ0-0.25ï¼Œè¶Šå¤§æ”¶æ•›è¶Šå¿«ä½†å¯èƒ½ä¸ç¨³å®šï¼‰
    
    è¿”å›:
        diffused_colors: æ‰©æ•£åçš„é¢œè‰² (N, 3)
    """
    from sklearn.neighbors import NearestNeighbors
    
    if len(vertex_colors) == 0:
        return vertex_colors.copy()
    
    valid_mask = weights > 0
    if valid_mask.sum() < 4:
        return vertex_colors.copy()
    
    # æ„å»ºé‚»æ¥å…³ç³»
    valid_positions = vertex_positions[valid_mask]
    valid_colors = vertex_colors[valid_mask].astype(np.float64)
    
    k = min(6, len(valid_positions) - 1)
    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(valid_positions)
    distances, indices = nbrs.kneighbors(valid_positions)
    
    # è¿­ä»£æ‰©æ•£
    diffused = valid_colors.copy()
    
    for iter_idx in range(iterations):
        new_diffused = diffused.copy()
        
        for i in range(len(diffused)):
            neighbor_idx = indices[i, 1:]
            neighbor_colors = diffused[neighbor_idx]
            
            # è®¡ç®—é¢œè‰²æ¢¯åº¦
            gradients = neighbor_colors - diffused[i]
            gradient_mag = np.linalg.norm(gradients, axis=1)
            
            # Perona-Malikæ‰©æ•£ç³»æ•°ï¼ˆè¾¹ç¼˜æŠ‘åˆ¶å‡½æ•°ï¼‰
            c = np.exp(-(gradient_mag / kappa)**2)
            
            # åŠ æƒæ‰©æ•£
            flux = (gradients * c[:, np.newaxis]).sum(axis=0)
            new_diffused[i] = diffused[i] + gamma * flux
        
        diffused = new_diffused
    
    # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
    diffused = np.clip(diffused, 0, 1)
    
    result = vertex_colors.copy()
    result[valid_mask] = diffused.astype(vertex_colors.dtype)
    return result


def edge_preserving_smooth(vertex_colors, vertex_positions, weights,
                           method="bilateral", **kwargs):
    """
    è¾¹ç¼˜ä¿æŒå¹³æ»‘ç»Ÿä¸€æ¥å£
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        method: å¹³æ»‘æ–¹æ³• "bilateral"/"anisotropic"
        **kwargs: æ–¹æ³•ç‰¹å®šå‚æ•°
    
    è¿”å›:
        smoothed_colors: å¹³æ»‘åçš„é¢œè‰² (N, 3)
    """
    if method == "bilateral":
        sigma_spatial = kwargs.get('sigma_spatial', 5.0)
        sigma_color = kwargs.get('sigma_color', 0.1)
        k_neighbors = kwargs.get('k_neighbors', 16)
        return bilateral_filter_texture(vertex_colors, vertex_positions, weights,
                                       sigma_spatial, sigma_color, k_neighbors)
    elif method == "anisotropic":
        iterations = kwargs.get('iterations', 10)
        kappa = kwargs.get('kappa', 50.0)
        gamma = kwargs.get('gamma', 0.1)
        return anisotropic_diffusion_texture(vertex_colors, vertex_positions, weights,
                                            iterations, kappa, gamma)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¹³æ»‘æ–¹æ³•: {method}")


def histogram_match_colors(source_colors, reference_colors, weights=None, 
                           clip_percentile=5.0):
    """
    ç›´æ–¹å›¾åŒ¹é…è¿›è¡Œè‰²å½©ä¸€è‡´æ€§æ ¡æ­£
    
    å‚æ•°:
        source_colors: æºé¢œè‰² (N, 3) èŒƒå›´0-1
        reference_colors: å‚è€ƒé¢œè‰² (M, 3)
        weights: æºé¢œè‰²æƒé‡ (N,)ï¼Œå¯é€‰
        clip_percentile: è£å‰ªç™¾åˆ†ä½ï¼ˆé¿å…æç«¯å€¼å½±å“ï¼‰
    
    è¿”å›:
        matched_colors: åŒ¹é…åçš„é¢œè‰² (N, 3)
    """
    if len(source_colors) == 0 or len(reference_colors) == 0:
        return source_colors.copy()
    
    matched = np.zeros_like(source_colors)
    
    # é€é€šé“åŒ¹é…
    for c in range(3):
        src_channel = source_colors[:, c]
        ref_channel = reference_colors[:, c]
        
        # è£å‰ªæç«¯å€¼
        src_min = np.percentile(src_channel, clip_percentile)
        src_max = np.percentile(src_channel, 100 - clip_percentile)
        ref_min = np.percentile(ref_channel, clip_percentile)
        ref_max = np.percentile(ref_channel, 100 - clip_percentile)
        
        # çº¿æ€§æ‹‰ä¼¸åŒ¹é…
        src_clipped = np.clip(src_channel, src_min, src_max)
        src_norm = (src_clipped - src_min) / (src_max - src_min + 1e-8)
        matched[:, c] = src_norm * (ref_max - ref_min) + ref_min
    
    # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
    matched = np.clip(matched, 0, 1)
    
    # å¦‚æœæä¾›äº†æƒé‡ï¼Œå¯¹ä½æƒé‡åŒºåŸŸä¿ç•™åŸå§‹é¢œè‰²
    if weights is not None:
        alpha = np.clip(weights, 0, 1)[:, np.newaxis]
        matched = alpha * matched + (1 - alpha) * source_colors
    
    return matched


def color_transfer(source_colors, reference_colors, preserve_luminance=True):
    """
    è‰²å½©ä¼ é€’ï¼ˆReinhardé£æ ¼ï¼‰
    
    å‚æ•°:
        source_colors: æºé¢œè‰² (N, 3) èŒƒå›´0-1
        reference_colors: å‚è€ƒé¢œè‰² (M, 3)
        preserve_luminance: æ˜¯å¦ä¿ç•™äº®åº¦ä¿¡æ¯
    
    è¿”å›:
        transferred_colors: ä¼ é€’åçš„é¢œè‰² (N, 3)
    """
    if len(source_colors) == 0 or len(reference_colors) == 0:
        return source_colors.copy()
    
    # è½¬æ¢åˆ°LABç©ºé—´
    src_lab = rgb_to_lab(source_colors)
    ref_lab = rgb_to_lab(reference_colors)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    src_mean = src_lab.mean(axis=0)
    src_std = src_lab.std(axis=0) + 1e-8
    ref_mean = ref_lab.mean(axis=0)
    ref_std = ref_lab.std(axis=0) + 1e-8
    
    # è‰²å½©ä¼ é€’
    transferred_lab = src_lab.copy()
    
    if preserve_luminance:
        # åªä¼ é€’è‰²åº¦ï¼ˆa*, b*é€šé“ï¼‰
        for c in [1, 2]:
            transferred_lab[:, c] = (src_lab[:, c] - src_mean[c]) / src_std[c]
            transferred_lab[:, c] = transferred_lab[:, c] * ref_std[c] + ref_mean[c]
    else:
        # ä¼ é€’æ‰€æœ‰é€šé“
        for c in range(3):
            transferred_lab[:, c] = (src_lab[:, c] - src_mean[c]) / src_std[c]
            transferred_lab[:, c] = transferred_lab[:, c] * ref_std[c] + ref_mean[c]
    
    # è½¬æ¢å›RGB
    transferred_colors = lab_to_rgb(transferred_lab)
    
    return transferred_colors


def color_correction(vertex_colors, reference_colors, weights=None,
                     method="histogram", **kwargs):
    """
    è‰²å½©ä¸€è‡´æ€§æ ¡æ­£ç»Ÿä¸€æ¥å£
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        reference_colors: å‚è€ƒé¢œè‰²ï¼ˆå¦‚å‰ä¸€å¸§æˆ–å…¨å±€å¹³å‡ï¼‰
        weights: é¡¶ç‚¹æƒé‡ (N,)
        method: æ ¡æ­£æ–¹æ³• "histogram"/"transfer"
        **kwargs: æ–¹æ³•ç‰¹å®šå‚æ•°
    
    è¿”å›:
        corrected_colors: æ ¡æ­£åçš„é¢œè‰² (N, 3)
    """
    if method == "histogram":
        clip_percentile = kwargs.get('clip_percentile', 5.0)
        return histogram_match_colors(vertex_colors, reference_colors, 
                                     weights, clip_percentile)
    elif method == "transfer":
        preserve_luminance = kwargs.get('preserve_luminance', True)
        return color_transfer(vertex_colors, reference_colors, preserve_luminance)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ¡æ­£æ–¹æ³•: {method}")


def post_process_texture(vertex_colors, vertex_positions, weights,
                        config=None, reference_colors=None):
    """
    çº¹ç†åå¤„ç†ä¸»æµç¨‹ï¼ˆç¬¬8æ­¥ä¼˜åŒ–ï¼‰
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰² (N, 3)
        vertex_positions: é¡¶ç‚¹3Dåæ ‡ (N, 3)
        weights: é¡¶ç‚¹æƒé‡ (N,)
        config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼Œä½¿ç”¨å…¨å±€é…ç½®ï¼‰
        reference_colors: å‚è€ƒé¢œè‰²ï¼ˆç”¨äºè‰²å½©æ ¡æ­£ï¼‰
    
    è¿”å›:
        processed_colors: å¤„ç†åçš„é¢œè‰² (N, 3)
        stats: å¤„ç†ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    if config is None:
        config = {
            'use_outlier_detection': USE_OUTLIER_DETECTION,
            'outlier_method': OUTLIER_DETECTION_METHOD,
            'outlier_zscore': OUTLIER_ZSCORE_THRESHOLD,
            'outlier_local_k': 8,
            'outlier_local_threshold': OUTLIER_LOCAL_THRESHOLD,
            'use_smooth': USE_EDGE_PRESERVING_SMOOTH,
            'smooth_method': SMOOTH_METHOD,
            'bilateral_sigma_spatial': BILATERAL_SIGMA_SPATIAL,
            'bilateral_sigma_color': BILATERAL_SIGMA_COLOR / 255.0,  # è½¬æ¢åˆ°0-1
            'anisotropic_iterations': ANISOTROPIC_ITERATIONS,
            'anisotropic_kappa': ANISOTROPIC_KAPPA / 255.0,  # è½¬æ¢åˆ°0-1
            'use_color_correction': USE_COLOR_CORRECTION,
            'color_method': COLOR_CORRECTION_METHOD,
            'histogram_clip': HISTOGRAM_MATCH_PERCENTILE,
            'transfer_preserve_lum': COLOR_TRANSFER_PRESERVE_LUMINANCE,
        }
    
    processed = vertex_colors.copy()
    stats = {}
    
    # 1. å¼‚å¸¸å€¼æ£€æµ‹ä¸ç§»é™¤
    if config['use_outlier_detection']:
        outlier_mask, outlier_count = detect_outliers(
            processed, vertex_positions, weights,
            method=config['outlier_method'],
            zscore_threshold=config['outlier_zscore'],
            local_k=config['outlier_local_k'],
            local_threshold=config['outlier_local_threshold']
        )
        
        # ç§»é™¤å¼‚å¸¸å€¼ï¼ˆå°†æƒé‡è®¾ä¸º0ï¼‰
        weights = weights.copy()
        weights[outlier_mask] = 0
        
        stats['outliers_detected'] = outlier_count
        stats['outliers_ratio'] = outlier_count / len(processed) if len(processed) > 0 else 0
    
    # 2. è¾¹ç¼˜ä¿æŒå¹³æ»‘
    if config['use_smooth']:
        if config['smooth_method'] == 'bilateral':
            processed = edge_preserving_smooth(
                processed, vertex_positions, weights,
                method='bilateral',
                sigma_spatial=config['bilateral_sigma_spatial'],
                sigma_color=config['bilateral_sigma_color'],
                k_neighbors=16
            )
        elif config['smooth_method'] == 'anisotropic':
            processed = edge_preserving_smooth(
                processed, vertex_positions, weights,
                method='anisotropic',
                iterations=config['anisotropic_iterations'],
                kappa=config['anisotropic_kappa'],
                gamma=0.1
            )
    
    # 3. è‰²å½©ä¸€è‡´æ€§æ ¡æ­£
    if config['use_color_correction'] and reference_colors is not None:
        if config['color_method'] == 'histogram':
            processed = color_correction(
                processed, reference_colors, weights,
                method='histogram',
                clip_percentile=config['histogram_clip']
            )
        elif config['color_method'] == 'transfer':
            processed = color_correction(
                processed, reference_colors, weights,
                method='transfer',
                preserve_luminance=config['transfer_preserve_lum']
            )
    
    return processed, stats


# ============================================================================
# ç¬¬3æ­¥ä¼˜åŒ–ï¼šåŒä¸‰æ¬¡æ’å€¼å‡½æ•°
# ============================================================================
def cubic_kernel(x, a=-0.5):
    """
    åŒä¸‰æ¬¡æ’å€¼æ ¸å‡½æ•°ï¼ˆCatmull-Romæ ·æ¡ï¼‰
    
    å‚æ•°:
        x: è·ç¦»ï¼ˆ0-2èŒƒå›´ï¼‰
        a: æ’å€¼å‚æ•°ï¼ˆ-0.75åˆ°-0.5ï¼Œ-0.5æ›´é”åˆ©ï¼Œ-0.75æ›´å¹³æ»‘ï¼‰
    
    è¿”å›:
        æƒé‡å€¼
    """
    x = np.abs(x)
    
    # 0 <= |x| < 1
    mask1 = x < 1
    # 1 <= |x| < 2
    mask2 = (x >= 1) & (x < 2)
    
    result = np.zeros_like(x)
    result[mask1] = (a + 2) * x[mask1]**3 - (a + 3) * x[mask1]**2 + 1
    result[mask2] = a * x[mask2]**3 - 5*a * x[mask2]**2 + 8*a * x[mask2] - 4*a
    
    return result

def bicubic_interpolate(img, u_f, v_f, a=-0.5):
    """
    åŒä¸‰æ¬¡æ’å€¼é‡‡æ ·
    
    å‚æ•°:
        img: è¾“å…¥å›¾åƒ (H, W, 3)
        u_f, v_f: æµ®ç‚¹åæ ‡æ•°ç»„
        a: æ’å€¼å‚æ•°
    
    è¿”å›:
        æ’å€¼åçš„é¢œè‰² (N, 3)
    """
    H, W = img.shape[:2]
    
    # è·å–16ä¸ªé‚»åŸŸåƒç´ çš„åæ ‡
    u_int = np.floor(u_f).astype(int)
    v_int = np.floor(v_f).astype(int)
    
    # è®¡ç®—ç›¸å¯¹ä½ç½®
    du = u_f - u_int
    dv = v_f - v_int
    
    # åˆå§‹åŒ–è¾“å‡º
    colors = np.zeros((len(u_f), 3), dtype=np.float32)
    
    # 16ä¸ªé‚»åŸŸåƒç´ ï¼ˆ4x4ç½‘æ ¼ï¼‰
    for i in range(-1, 3):
        for j in range(-1, 3):
            # é‚»åŸŸåæ ‡
            u_neighbor = np.clip(u_int + i, 0, W - 1)
            v_neighbor = np.clip(v_int + j, 0, H - 1)
            
            # è®¡ç®—æƒé‡
            weight_u = cubic_kernel(i - du, a)
            weight_v = cubic_kernel(j - dv, a)
            weight = weight_u * weight_v
            
            # ç´¯åŠ åŠ æƒé¢œè‰²
            colors += img[v_neighbor, u_neighbor] * weight[:, np.newaxis]
    
    return colors

# ============================================================================
# ç¬¬4æ­¥ä¼˜åŒ–ï¼šæ™ºèƒ½è§†è§’é€‰æ‹©ä¸åŠ æƒå‡½æ•°
# ============================================================================
def compute_view_angle_weight(normals, view_dirs, max_angle_deg=75.0):
    """
    è®¡ç®—è§†è§’è´¨é‡æƒé‡ï¼ˆåŸºäºæ³•å‘å’Œè§†çº¿å¤¹è§’ï¼‰
    
    å‚æ•°:
        normals: é¡¶ç‚¹æ³•å‘é‡ (N, 3)ï¼Œå·²å½’ä¸€åŒ–
        view_dirs: è§†çº¿æ–¹å‘ (N, 3)ï¼Œå·²å½’ä¸€åŒ–ï¼ŒæŒ‡å‘ç›¸æœº
        max_angle_deg: æœ€å¤§æœ‰æ•ˆè§†è§’ï¼ˆåº¦ï¼‰
    
    è¿”å›:
        è§†è§’æƒé‡ (N,)ï¼ŒèŒƒå›´[0, 1]ï¼Œ0åº¦æœ€ä¼˜ï¼ˆæƒé‡1ï¼‰ï¼Œ90åº¦æœ€å·®ï¼ˆæƒé‡0ï¼‰
    """
    # è®¡ç®—æ³•å‘å’Œè§†çº¿çš„å¤¹è§’ä½™å¼¦å€¼
    cos_angles = np.sum(normals * view_dirs, axis=1)
    cos_angles = np.clip(cos_angles, -1, 1)
    
    # è½¬æ¢ä¸ºè§’åº¦
    angles_deg = np.degrees(np.arccos(cos_angles))
    
    # ä½¿ç”¨å¹³æ»‘è¡°å‡å‡½æ•°ï¼šåœ¨max_angleä¹‹å‰ç¼“æ…¢è¡°å‡ï¼Œä¹‹åå¿«é€Ÿè¡°å‡
    # ä½¿ç”¨cos^2å‡½æ•°ä½œä¸ºæƒé‡ï¼ˆæ›´å¹³æ»‘çš„è¡°å‡ï¼‰
    max_angle_rad = np.radians(max_angle_deg)
    
    # è¶…è¿‡æœ€å¤§è§’åº¦çš„è®¾ä¸º0
    weights = np.where(
        angles_deg <= max_angle_deg,
        (cos_angles ** 2),  # 0-max_angleèŒƒå›´å†…ï¼šcos^2è¡°å‡
        0.0                  # è¶…è¿‡max_angleï¼šæƒé‡ä¸º0
    )
    
    return weights

def compute_distance_weight(distances, falloff=2.0):
    """
    è®¡ç®—è·ç¦»æƒé‡ï¼ˆåŸºäºç›¸æœºåˆ°è¡¨é¢è·ç¦»ï¼‰
    
    å‚æ•°:
        distances: ç›¸æœºåˆ°è¡¨é¢çš„è·ç¦» (N,)
        falloff: è¡°å‡æŒ‡æ•°ï¼ˆè¶Šå¤§è¡°å‡è¶Šå¿«ï¼‰
    
    è¿”å›:
        è·ç¦»æƒé‡ (N,)ï¼ŒèŒƒå›´[0, 1]ï¼Œè¿‘è·ç¦»æƒé‡é«˜ï¼Œè¿œè·ç¦»æƒé‡ä½
    """
    # å½’ä¸€åŒ–è·ç¦»ï¼ˆç›¸å¯¹äºæœ€å°è·ç¦»ï¼‰
    min_dist = np.min(distances)
    max_dist = np.max(distances)
    
    if max_dist - min_dist < 1e-6:
        # æ‰€æœ‰è·ç¦»ç›¸åŒï¼Œè¿”å›å‡åŒ€æƒé‡
        return np.ones_like(distances)
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    normalized_dist = (distances - min_dist) / (max_dist - min_dist)
    
    # ä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼šweight = exp(-falloff * normalized_dist)
    # æˆ–ä½¿ç”¨å¹‚å‡½æ•°ï¼šweight = (1 - normalized_dist)^falloff
    weights = (1.0 - normalized_dist) ** falloff
    
    return weights

def compute_combined_weight(view_weights, dist_weights, quality_scores,
                           view_alpha=0.4, dist_alpha=0.3, quality_alpha=0.3):
    """
    è®¡ç®—ç»¼åˆæƒé‡ï¼ˆè§†è§’ + è·ç¦» + å›¾åƒè´¨é‡ï¼‰
    
    å‚æ•°:
        view_weights: è§†è§’æƒé‡ (N,)
        dist_weights: è·ç¦»æƒé‡ (N,)
        quality_scores: å›¾åƒè´¨é‡åˆ†æ•° (N,)ï¼ŒèŒƒå›´[0, 1]
        view_alpha: è§†è§’æƒé‡ç³»æ•°
        dist_alpha: è·ç¦»æƒé‡ç³»æ•°
        quality_alpha: å›¾åƒè´¨é‡æƒé‡ç³»æ•°
    
    è¿”å›:
        ç»¼åˆæƒé‡ (N,)ï¼ŒèŒƒå›´[0, 1]
    """
    # å½’ä¸€åŒ–ç³»æ•°ï¼ˆç¡®ä¿æ€»å’Œä¸º1ï¼‰
    total_alpha = view_alpha + dist_alpha + quality_alpha
    view_alpha /= total_alpha
    dist_alpha /= total_alpha
    quality_alpha /= total_alpha
    
    # åŠ æƒç»„åˆ
    combined = (view_alpha * view_weights +
                dist_alpha * dist_weights +
                quality_alpha * quality_scores)
    
    # ç¡®ä¿èŒƒå›´åœ¨[0, 1]
    combined = np.clip(combined, 0.0, 1.0)
    
    return combined

# ============================================================================
# ç¬¬5æ­¥ä¼˜åŒ–ï¼šåŸºäºæ–¹å·®çš„æ¥ç¼å¹³æ»‘ (Variance-based Seam Smoothing)
# ============================================================================

def compute_local_variance(mesh, vertex_colors, vertex_weights, k_neighbors=10):
    """
    è®¡ç®—æ¯ä¸ªé¡¶ç‚¹çš„å±€éƒ¨é¢œè‰²æ–¹å·®
    
    å‚æ•°:
        mesh: Open3Dä¸‰è§’ç½‘æ ¼
        vertex_colors: é¡¶ç‚¹é¢œè‰²ç´¯ç§¯å€¼ (N, 3)
        vertex_weights: é¡¶ç‚¹æƒé‡ç´¯ç§¯å€¼ (N,)
        k_neighbors: é‚»åŸŸé¡¶ç‚¹æ•°é‡
    
    è¿”å›:
        å±€éƒ¨æ–¹å·®å€¼ (N,) èŒƒå›´[0, +inf]ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºæ¥ç¼å¯èƒ½æ€§è¶Šé«˜
    """
    vertices_np = np.asarray(mesh.vertices)
    n_vertices = len(vertices_np)
    
    # æ„å»ºKDæ ‘ç”¨äºé‚»åŸŸæœç´¢
    from scipy.spatial import cKDTree
    kdtree = cKDTree(vertices_np)
    
    # è®¡ç®—å½“å‰é¡¶ç‚¹é¢œè‰²ï¼ˆåŠ æƒå¹³å‡ï¼‰
    current_colors = np.zeros_like(vertex_colors)
    non_zero = vertex_weights > 0
    current_colors[non_zero] = vertex_colors[non_zero] / vertex_weights[non_zero, np.newaxis]
    
    # è®¡ç®—å±€éƒ¨æ–¹å·®
    variances = np.zeros(n_vertices)
    
    for i in range(n_vertices):
        if vertex_weights[i] == 0:
            variances[i] = 0.0  # æœªç€è‰²é¡¶ç‚¹æ–¹å·®ä¸º0
            continue
        
        # æŸ¥è¯¢kä¸ªæœ€è¿‘é‚»
        distances, indices = kdtree.query(vertices_np[i], k=k_neighbors+1)
        neighbor_indices = indices[1:]  # æ’é™¤è‡ªå·±
        
        # åªè€ƒè™‘å·²ç€è‰²çš„é‚»å±…
        valid_neighbors = neighbor_indices[vertex_weights[neighbor_indices] > 0]
        
        if len(valid_neighbors) == 0:
            variances[i] = 0.0
            continue
        
        # è®¡ç®—é‚»åŸŸé¢œè‰²æ–¹å·®
        neighbor_colors = current_colors[valid_neighbors]
        color_diff = neighbor_colors - current_colors[i]
        variance = np.mean(np.sum(color_diff ** 2, axis=1))
        variances[i] = variance
    
    return variances


def detect_seam_regions(mesh, vertex_colors, vertex_weights, variance_threshold=0.01, k_neighbors=10):
    """
    æ£€æµ‹å¯èƒ½å­˜åœ¨æ¥ç¼çš„åŒºåŸŸ
    
    å‚æ•°:
        mesh: Open3Dä¸‰è§’ç½‘æ ¼
        vertex_colors: é¡¶ç‚¹é¢œè‰²ç´¯ç§¯å€¼ (N, 3)
        vertex_weights: é¡¶ç‚¹æƒé‡ç´¯ç§¯å€¼ (N,)
        variance_threshold: æ–¹å·®é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯æ¥ç¼
        k_neighbors: é‚»åŸŸé¡¶ç‚¹æ•°é‡
    
    è¿”å›:
        seam_mask: æ¥ç¼æ©ç  (N,) boolæ•°ç»„ï¼ŒTrueè¡¨ç¤ºå¯èƒ½æ˜¯æ¥ç¼
        variances: å±€éƒ¨æ–¹å·®å€¼ (N,)
    """
    variances = compute_local_variance(mesh, vertex_colors, vertex_weights, k_neighbors)
    seam_mask = variances > variance_threshold
    return seam_mask, variances


def apply_adaptive_smoothing(mesh, vertex_colors, vertex_weights, seam_mask, 
                             smoothing_strength=0.5, k_neighbors=10):
    """
    å¯¹æ¥ç¼åŒºåŸŸè¿›è¡Œè‡ªé€‚åº”å¹³æ»‘
    
    å‚æ•°:
        mesh: Open3Dä¸‰è§’ç½‘æ ¼
        vertex_colors: é¡¶ç‚¹é¢œè‰²ç´¯ç§¯å€¼ (N, 3)
        vertex_weights: é¡¶ç‚¹æƒé‡ç´¯ç§¯å€¼ (N,)
        seam_mask: æ¥ç¼æ©ç  (N,) boolæ•°ç»„
        smoothing_strength: å¹³æ»‘å¼ºåº¦ [0, 1]ï¼Œ0=ä¸å¹³æ»‘ï¼Œ1=å®Œå…¨å¹³æ»‘
        k_neighbors: é‚»åŸŸé¡¶ç‚¹æ•°é‡
    
    è¿”å›:
        å¹³æ»‘åçš„é¡¶ç‚¹é¢œè‰² (N, 3)
    """
    vertices_np = np.asarray(mesh.vertices)
    n_vertices = len(vertices_np)
    
    # æ„å»ºKDæ ‘
    from scipy.spatial import cKDTree
    kdtree = cKDTree(vertices_np)
    
    # è®¡ç®—å½“å‰é¡¶ç‚¹é¢œè‰²
    current_colors = np.zeros_like(vertex_colors)
    non_zero = vertex_weights > 0
    current_colors[non_zero] = vertex_colors[non_zero] / vertex_weights[non_zero, np.newaxis]
    
    # åˆ›å»ºå¹³æ»‘åçš„é¢œè‰²å‰¯æœ¬
    smoothed_colors = current_colors.copy()
    
    # åªå¯¹æ¥ç¼åŒºåŸŸè¿›è¡Œå¹³æ»‘
    seam_indices = np.where(seam_mask)[0]
    
    for i in seam_indices:
        if vertex_weights[i] == 0:
            continue
        
        # æŸ¥è¯¢kä¸ªæœ€è¿‘é‚»
        distances, indices = kdtree.query(vertices_np[i], k=k_neighbors+1)
        neighbor_indices = indices[1:]  # æ’é™¤è‡ªå·±
        
        # åªè€ƒè™‘å·²ç€è‰²çš„é‚»å±…
        valid_neighbors = neighbor_indices[vertex_weights[neighbor_indices] > 0]
        
        if len(valid_neighbors) == 0:
            continue
        
        # åŸºäºè·ç¦»çš„æƒé‡ï¼ˆè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§ï¼‰
        neighbor_distances = distances[1:][vertex_weights[neighbor_indices] > 0]
        neighbor_weights = 1.0 / (neighbor_distances + 1e-6)
        neighbor_weights = neighbor_weights / np.sum(neighbor_weights)
        
        # è®¡ç®—åŠ æƒå¹³å‡é¢œè‰²
        neighbor_colors = current_colors[valid_neighbors]
        
        # ç¬¬6æ­¥ä¼˜åŒ–ï¼šå¯é€‰åœ¨LABç©ºé—´æ··åˆï¼ˆæ›´å¥½çš„æ„ŸçŸ¥ä¸€è‡´æ€§ï¼‰
        if USE_LAB_COLOR_SPACE:
            # åœ¨LABç©ºé—´æ··åˆé‚»åŸŸé¢œè‰²
            all_colors = np.vstack([current_colors[i:i+1], neighbor_colors])
            all_weights = np.concatenate([[1 - smoothing_strength], neighbor_weights * smoothing_strength])
            all_weights = all_weights / np.sum(all_weights)  # å½’ä¸€åŒ–
            
            avg_color = mix_colors_in_lab(
                all_colors, all_weights,
                l_weight=LAB_L_WEIGHT,
                normalize_l=LAB_NORMALIZE_L,
                l_clip_percentile=LAB_L_CLIP_PERCENTILE
            )
        else:
            # RGBç©ºé—´ç®€å•åŠ æƒå¹³å‡
            avg_color = np.sum(neighbor_colors * neighbor_weights[:, np.newaxis], axis=0)
            avg_color = (1 - smoothing_strength) * current_colors[i] + smoothing_strength * avg_color
        
        smoothed_colors[i] = avg_color
    
    return smoothed_colors

# ============================================================================
# ç¬¬6æ­¥ä¼˜åŒ–ï¼šLABè‰²å½©ç©ºé—´è½¬æ¢å‡½æ•°
# ============================================================================
def rgb_to_lab(rgb):
    """
    å°†RGBé¢œè‰²è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´
    
    LABè‰²å½©ç©ºé—´ä¼˜åŠ¿ï¼š
    - Lé€šé“ï¼šäº®åº¦ï¼ˆ0-100ï¼‰ï¼Œä¸äººçœ¼æ„ŸçŸ¥ä¸€è‡´
    - Aé€šé“ï¼šç»¿è‰²åˆ°çº¢è‰²ï¼ˆ-128åˆ°127ï¼‰
    - Bé€šé“ï¼šè“è‰²åˆ°é»„è‰²ï¼ˆ-128åˆ°127ï¼‰
    - åˆ†ç¦»äº®åº¦å’Œè‰²åº¦ï¼Œå‡å°‘å…‰ç…§å½±å“
    - åœ¨LABç©ºé—´æ··åˆé¢œè‰²æ›´ç¬¦åˆäººçœ¼æ„ŸçŸ¥
    
    å‚æ•°:
        rgb: RGBé¢œè‰² (N, 3) æˆ– (3,)ï¼ŒèŒƒå›´[0, 1]
    
    è¿”å›:
        lab: LABé¢œè‰² (N, 3) æˆ– (3,)
             L: [0, 100]
             A, B: [-128, 127]
    """
    # ç¡®ä¿è¾“å…¥æ˜¯2Dæ•°ç»„
    input_shape = rgb.shape
    if rgb.ndim == 1:
        rgb = rgb.reshape(1, -1)
    
    # 1. RGB to XYZï¼ˆä½¿ç”¨sRGBæ ‡å‡†ï¼‰
    # å…ˆè¿›è¡Œgammaæ ¡æ­£ï¼ˆé€†sRGBå˜æ¢ï¼‰
    rgb_linear = np.where(
        rgb > 0.04045,
        ((rgb + 0.055) / 1.055) ** 2.4,
        rgb / 12.92
    )
    
    # RGB to XYZè½¬æ¢çŸ©é˜µï¼ˆD65å…‰æºï¼‰
    transform_matrix = np.array([
        [0.4124564, 0.3575761, 0.1804375],
        [0.2126729, 0.7151522, 0.0721750],
        [0.0193339, 0.1191920, 0.9503041]
    ])
    
    xyz = rgb_linear @ transform_matrix.T
    
    # 2. XYZ to LAB
    # D65æ ‡å‡†å…‰æºç™½ç‚¹
    xyz_n = np.array([0.95047, 1.00000, 1.08883])
    
    # å½’ä¸€åŒ–XYZ
    xyz_norm = xyz / xyz_n
    
    # få‡½æ•°ï¼ˆLABè½¬æ¢çš„éçº¿æ€§éƒ¨åˆ†ï¼‰
    delta = 6.0 / 29.0
    def f(t):
        return np.where(
            t > delta3,
            t(1/3),
            t / (3 * delta2) + (4/29)
        )
    
    fx = f(xyz_norm[:, 0])
    fy = f(xyz_norm[:, 1])
    fz = f(xyz_norm[:, 2])
    
    # è®¡ç®—LAB
    L = 116 * fy - 16
    A = 500 * (fx - fy)
    B = 200 * (fy - fz)
    
    lab = np.stack([L, A, B], axis=-1)
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    if len(input_shape) == 1:
        lab = lab.reshape(input_shape)
    
    return lab

def lab_to_rgb(lab):
    """
    å°†LABé¢œè‰²è½¬æ¢åˆ°RGBè‰²å½©ç©ºé—´
    
    å‚æ•°:
        lab: LABé¢œè‰² (N, 3) æˆ– (3,)
             L: [0, 100]
             A, B: [-128, 127]
    
    è¿”å›:
        rgb: RGBé¢œè‰² (N, 3) æˆ– (3,)ï¼ŒèŒƒå›´[0, 1]
    """
    # ç¡®ä¿è¾“å…¥æ˜¯2Dæ•°ç»„
    input_shape = lab.shape
    if lab.ndim == 1:
        lab = lab.reshape(1, -1)
    
    L = lab[:, 0]
    A = lab[:, 1]
    B = lab[:, 2]
    
    # 1. LAB to XYZ
    fy = (L + 16) / 116
    fx = A / 500 + fy
    fz = fy - B / 200
    
    # fé€†å‡½æ•°
    delta = 6.0 / 29.0
    def f_inv(t):
        return np.where(
            t > delta,
            t3,
            3 * delta2 * (t - 4/29)
        )
    
    xyz_norm = np.stack([
        f_inv(fx),
        f_inv(fy),
        f_inv(fz)
    ], axis=-1)
    
    # D65æ ‡å‡†å…‰æºç™½ç‚¹
    xyz_n = np.array([0.95047, 1.00000, 1.08883])
    xyz = xyz_norm * xyz_n
    
    # 2. XYZ to RGB
    # XYZ to RGBè½¬æ¢çŸ©é˜µï¼ˆD65å…‰æºï¼‰
    transform_matrix = np.array([
        [ 3.2404542, -1.5371385, -0.4985314],
        [-0.9692660,  1.8760108,  0.0415560],
        [ 0.0556434, -0.2040259,  1.0572252]
    ])
    
    rgb_linear = xyz @ transform_matrix.T
    
    # 3. åº”ç”¨sRGB gammaæ ¡æ­£
    rgb = np.where(
        rgb_linear > 0.0031308,
        1.055 * (rgb_linear  (1/2.4)) - 0.055,
        12.92 * rgb_linear
    )
    
    # è£å‰ªåˆ°[0, 1]èŒƒå›´
    rgb = np.clip(rgb, 0, 1)
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    if len(input_shape) == 1:
        rgb = rgb.reshape(input_shape)
    
    return rgb

def mix_colors_in_lab(colors, weights, l_weight=0.5, normalize_l=True, l_clip_percentile=2.0):
    """
    åœ¨LABè‰²å½©ç©ºé—´ä¸­æ··åˆé¢œè‰²ï¼ˆå‡å°‘å…‰ç…§å½±å“ï¼‰
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - Lé€šé“ï¼ˆäº®åº¦ï¼‰å¯é€‰å½’ä¸€åŒ–ï¼Œå‡å°‘ä¸åŒå…‰ç…§æ¡ä»¶çš„å½±å“
    - A/Bé€šé“ï¼ˆè‰²åº¦ï¼‰ä¿ç•™å®Œæ•´ä¿¡æ¯
    - åŠ æƒæ··åˆåè½¬å›RGB
    
    å‚æ•°:
        colors: RGBé¢œè‰²æ•°ç»„ (N, 3)ï¼ŒèŒƒå›´[0, 1]
        weights: æƒé‡ (N,)ï¼Œå·²å½’ä¸€åŒ–
        l_weight: Lé€šé“æƒé‡ï¼ˆ0-1ï¼‰ï¼Œè¶Šé«˜è¶Šä¿ç•™äº®åº¦å·®å¼‚
        normalize_l: æ˜¯å¦å½’ä¸€åŒ–Lé€šé“ï¼ˆå‡å°‘å…‰ç…§å½±å“ï¼‰
        l_clip_percentile: Lé€šé“è£å‰ªç™¾åˆ†ä½ï¼ˆé¿å…æç«¯å€¼ï¼‰
    
    è¿”å›:
        mixed_rgb: æ··åˆåçš„RGBé¢œè‰² (3,)ï¼ŒèŒƒå›´[0, 1]
    """
    if len(colors) == 0:
        return np.array([0.5, 0.5, 0.5])
    
    # è½¬æ¢åˆ°LABç©ºé—´
    lab_colors = rgb_to_lab(colors)  # (N, 3)
    
    L = lab_colors[:, 0]  # (N,)
    A = lab_colors[:, 1]
    B = lab_colors[:, 2]
    
    # å¯é€‰ï¼šå½’ä¸€åŒ–Lé€šé“ï¼ˆå‡å°‘å…‰ç…§å½±å“ï¼‰
    if normalize_l and len(L) > 1:
        # ä½¿ç”¨ç™¾åˆ†ä½è£å‰ªé¿å…æç«¯å€¼
        L_min = np.percentile(L, l_clip_percentile)
        L_max = np.percentile(L, 100 - l_clip_percentile)
        
        if L_max - L_min > 1e-6:
            L_normalized = (L - L_min) / (L_max - L_min) * 100
            L_normalized = np.clip(L_normalized, 0, 100)
            
            # æ··åˆåŸå§‹Lå’Œå½’ä¸€åŒ–L
            L = l_weight * L + (1 - l_weight) * L_normalized
    
    # åŠ æƒå¹³å‡ï¼ˆåœ¨LABç©ºé—´ï¼‰
    L_mixed = np.sum(L * weights)
    A_mixed = np.sum(A * weights)
    B_mixed = np.sum(B * weights)
    
    # è½¬å›RGB
    lab_mixed = np.array([L_mixed, A_mixed, B_mixed])
    rgb_mixed = lab_to_rgb(lab_mixed)
    
    return rgb_mixed

# ============================================================================
# è½¦è¾†æ£€æµ‹ä¸å»é™¤å‡½æ•°
# ============================================================================
def detect_vehicles(depth_measured, depth_rendered, threshold=0.5, min_depth=0.1):
    """
    åŸºäºæ·±åº¦å·®å¼‚æ£€æµ‹è½¦è¾†ä½ç½®ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œå‘åå…¼å®¹ï¼‰
    
    åŸç†ï¼šmeshåªåŒ…å«åœ°é¢ï¼Œdepthå›¾åŒ…å«è½¦è¾†
    å½“ depth_measured >> depth_rendered æ—¶ï¼Œè¯´æ˜æœ‰è½¦è¾†é®æŒ¡
    
    å‚æ•°:
        depth_measured: depthå›¾çš„æ·±åº¦ (H, W)
        depth_rendered: meshæ¸²æŸ“æ·±åº¦ (H, W) 
        threshold: é«˜åº¦å·®é˜ˆå€¼ï¼ˆç±³ï¼‰ï¼Œè½¦è¾†é«˜åº¦
        min_depth: æœ€å°æœ‰æ•ˆæ·±åº¦
    
    è¿”å›:
        vehicle_mask: å¸ƒå°”æ•°ç»„ (H, W)ï¼ŒTrue=è½¦è¾†ä½ç½®
    """
    # è®¡ç®—æ·±åº¦å·®å¼‚ï¼ˆæ­£å€¼ = æœ‰ç‰©ä½“åœ¨meshå‰é¢ï¼‰
    depth_diff = depth_measured - depth_rendered
    
    # è½¦è¾†maskï¼šæ·±åº¦å·®å¼‚å¤§äºé˜ˆå€¼ï¼Œä¸”ä¸¤ä¸ªæ·±åº¦éƒ½æœ‰æ•ˆ
    vehicle_mask = (depth_diff > threshold) & \
                   (depth_measured > min_depth) & \
                   (depth_rendered > min_depth)
    
    return vehicle_mask


def detect_vehicles_multimodal(depth_obs, depth_tsdf, normals=None, points_3d=None, 
                                config=None):
    """
    å››æ¨¡æ€è½¦è¾†æ£€æµ‹ï¼ˆåˆ©ç”¨OSM-TSDFå…ˆéªŒï¼‰
    
    åŸç†ï¼šç»¼åˆå››ç§å‡ ä½•çº¿ç´¢è¿›è¡Œè½¦è¾†æ£€æµ‹
    1. æ³•å‘æ£€æµ‹ï¼šåœ°é¢æ³•å‘é‡æ¥è¿‘å‚ç›´
    2. é«˜åº¦è¿‡æ»¤ï¼šè½¦è¾†ä½äºåœ°é¢ä¹‹ä¸Šç‰¹å®šé«˜åº¦èŒƒå›´
    3. æ·±åº¦ä¸è¿ç»­ï¼šè½¦è¾†è¾¹ç¼˜æ·±åº¦æ¢¯åº¦å¤§
    4. TSDFæ·±åº¦ä¸€è‡´æ€§ï¼šè§‚æµ‹æ·±åº¦ < TSDFæ·±åº¦ï¼ˆå‰æ™¯é®æŒ¡ï¼‰
    
    å‚æ•°:
        depth_obs: è§‚æµ‹æ·±åº¦å›¾ (H, W)
        depth_tsdf: TSDFæ¸²æŸ“æ·±åº¦ (H, W)
        normals: è¡¨é¢æ³•å‘é‡ (H, W, 3)ï¼Œç”¨äºæ³•å‘æ£€æµ‹
        points_3d: ä¸‰ç»´ç‚¹äº‘ (H, W, 3)ï¼Œç”¨äºé«˜åº¦è¿‡æ»¤
        config: é…ç½®å­—å…¸
    
    è¿”å›:
        vehicle_mask: å¸ƒå°”æ•°ç»„ (H, W)ï¼ŒTrue=è½¦è¾†ä½ç½®
        cue_masks: å„çº¿ç´¢çš„ç‹¬ç«‹æ£€æµ‹ç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
    """
    if config is None:
        config = {
            'use_ground_normal': USE_GROUND_NORMAL,
            'ground_normal_threshold': GROUND_NORMAL_THRESHOLD,
            'use_height_filter': USE_HEIGHT_FILTER,
            'height_min': VEHICLE_HEIGHT_MIN,
            'height_max': VEHICLE_HEIGHT_MAX,
            'use_depth_discontinuity': USE_DEPTH_DISCONTINUITY,
            'gradient_threshold': DEPTH_GRADIENT_THRESHOLD,
            'use_depth_consistency': USE_TSDF_DEPTH_CONSISTENCY,
            'depth_diff_threshold': DEPTH_DIFF_THRESHOLD,
            'depth_noise_tolerance': DEPTH_NOISE_TOLERANCE,
            'require_all_cues': REQUIRE_ALL_CUES,
            'min_depth': MIN_DEPTH,
            'max_depth': MAX_DEPTH,
        }
    
    H, W = depth_obs.shape
    cue_masks = {}
    
    # ========== çº¿ç´¢1: åœ°é¢æ³•å‘æ£€æµ‹ ==========
    if config['use_ground_normal'] and normals is not None:
        # æ³•å‘é‡çš„Zåˆ†é‡ï¼ˆå‚ç›´åˆ†é‡ï¼‰
        normal_z = normals[:, :, 2]
        # æ¥è¿‘å‚ç›´å‘ä¸Šçš„ä¸ºåœ°é¢
        ground_mask = normal_z > config['ground_normal_threshold']
        cue_masks['ground_normal'] = ground_mask
    else:
        ground_mask = np.ones((H, W), dtype=bool)
        cue_masks['ground_normal'] = None
    
    # ========== çº¿ç´¢2: è½¦è¾†é«˜åº¦èŒƒå›´è¿‡æ»¤ ==========
    if config['use_height_filter'] and points_3d is not None:
        # è·å–ç‚¹çš„Zåæ ‡ï¼ˆé«˜åº¦ï¼‰
        heights = points_3d[:, :, 2]
        # ä¼°è®¡åœ°é¢é«˜åº¦ï¼ˆå–æœ€å°å€¼çš„ä¸­ä½æ•°ï¼‰
        valid_heights = heights[depth_obs > 0]
        if len(valid_heights) > 100:
            ground_height = np.percentile(valid_heights, 10)
        else:
            ground_height = 0.0
        
        # ç›¸å¯¹é«˜åº¦
        relative_height = heights - ground_height
        # è½¦è¾†é«˜åº¦èŒƒå›´
        height_mask = (relative_height >= config['height_min']) & \
                      (relative_height <= config['height_max'])
        cue_masks['height_filter'] = height_mask
    else:
        height_mask = np.ones((H, W), dtype=bool)
        cue_masks['height_filter'] = None
    
    # ========== çº¿ç´¢3: æ·±åº¦ä¸è¿ç»­æ€§æ£€æµ‹ ==========
    if config['use_depth_discontinuity']:
        # è®¡ç®—æ·±åº¦æ¢¯åº¦ï¼ˆSobelç®—å­ï¼‰
        grad_x = cv2.Sobel(depth_obs, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(depth_obs, cv2.CV_64F, 0, 1, ksize=3)
        depth_gradient = np.sqrt(grad_x**2 + grad_y**2)
        
        # æ·±åº¦çªå˜åŒºåŸŸï¼ˆè½¦è¾†è¾¹ç¼˜ï¼‰
        discontinuity_mask = depth_gradient > config['gradient_threshold']
        cue_masks['depth_discontinuity'] = discontinuity_mask
    else:
        discontinuity_mask = np.ones((H, W), dtype=bool)
        cue_masks['depth_discontinuity'] = None
    
    # ========== çº¿ç´¢4: TSDFæ·±åº¦ä¸€è‡´æ€§æ£€æµ‹ï¼ˆæ–°å¢ï¼ï¼‰==========
    if config['use_depth_consistency']:
        # æ·±åº¦å·®å¼‚ï¼šTSDFç†è®ºæ·±åº¦ - è§‚æµ‹æ·±åº¦
        depth_diff = depth_tsdf - depth_obs
        
        # å½“è§‚æµ‹æ·±åº¦æ˜¾è‘—å°äºTSDFæ·±åº¦æ—¶ï¼Œè¯´æ˜æœ‰å‰æ™¯é®æŒ¡ï¼ˆè½¦è¾†ï¼‰
        # D_TSDF - D_obs > threshold â†’ å‰æ™¯ç‰©ä½“
        consistency_mask = depth_diff > config['depth_diff_threshold']
        
        # æ·±åº¦æœ‰æ•ˆæ€§æ£€æŸ¥
        valid_obs = (depth_obs > config['min_depth']) & (depth_obs < config['max_depth'])
        valid_tsdf = (depth_tsdf > config['min_depth']) & (depth_tsdf < config['max_depth'])
        valid_mask = valid_obs & valid_tsdf
        
        # ç»¼åˆåˆ¤æ–­
        consistency_mask = consistency_mask & valid_mask
        cue_masks['depth_consistency'] = consistency_mask
    else:
        consistency_mask = np.ones((H, W), dtype=bool)
        cue_masks['depth_consistency'] = None
    
    # ========== å¤šæ¨¡æ€èåˆ ==========
    if config['require_all_cues']:
        # ANDé€»è¾‘ï¼šæ‰€æœ‰çº¿ç´¢éƒ½æ»¡è¶³
        vehicle_mask = ground_mask & height_mask & discontinuity_mask & consistency_mask
    else:
        # ORé€»è¾‘ï¼šä»»æ„çº¿ç´¢æ»¡è¶³
        vehicle_mask = ground_mask | height_mask | discontinuity_mask | consistency_mask
    
    return vehicle_mask, cue_masks

def refine_vehicle_mask(mask, dilation=5):
    """
    å½¢æ€å­¦å¤„ç†ï¼šå¡«å……è½¦è¾†å†…éƒ¨ç©ºæ´ã€å¹³æ»‘è¾¹ç¼˜ã€æ‰©å¤§è¦†ç›–èŒƒå›´
    
    å‚æ•°:
        mask: å¸ƒå°”æ•°ç»„ (H, W)
        dilation: è†¨èƒ€åŠå¾„ï¼ˆåƒç´ ï¼‰
    
    è¿”å›:
        refined_mask: å¤„ç†åçš„å¸ƒå°”æ•°ç»„ (H, W)
    """
    if not np.any(mask):
        return mask
    
    # è½¬æ¢ä¸ºuint8
    mask_uint8 = mask.astype(np.uint8)
    
    # åˆ›å»ºæ¤­åœ†å½¢ç»“æ„å…ƒç´ 
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                       (dilation*2+1, dilation*2+1))
    
    # é—­è¿ç®—ï¼šå¡«å……è½¦è¾†å†…éƒ¨ç©ºæ´
    mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel)
    
    # è†¨èƒ€ï¼šæ‰©å¤§maskï¼Œç¡®ä¿å®Œå…¨è¦†ç›–è½¦è¾†ï¼ˆåŒ…æ‹¬è¾¹ç¼˜ï¼‰
    mask_uint8 = cv2.dilate(mask_uint8, kernel, iterations=1)
    
    return mask_uint8.astype(bool)

def fill_empty_vertices(vertex_colors, vertex_weights, vertices, k=8):
    """
    ä½¿ç”¨Kè¿‘é‚»æ’å€¼å¡«å……æƒé‡ä¸º0çš„é¡¶ç‚¹ï¼ˆå®Œå…¨æœªæŠ•å½±çš„åŒºåŸŸï¼‰
    
    åº”ç”¨åœºæ™¯ï¼šè½¦è¾†é®æŒ¡å¯¼è‡´æŸäº›åœ°é¢åŒºåŸŸæ²¡æœ‰çº¹ç†
    
    å‚æ•°:
        vertex_colors: é¡¶ç‚¹é¢œè‰²æ•°ç»„ (N, 3)
        vertex_weights: é¡¶ç‚¹æƒé‡æ•°ç»„ (N,)
        vertices: é¡¶ç‚¹åæ ‡æ•°ç»„ (N, 3)
        k: Kè¿‘é‚»æ•°é‡
    
    è¿”å›:
        filled_colors: å¡«å……åçš„é¢œè‰²æ•°ç»„ (N, 3)
    """
    from scipy.spatial import KDTree
    
    # æ‰¾åˆ°ç©ºç™½é¡¶ç‚¹ï¼ˆæƒé‡ä¸º0ï¼‰
    empty_mask = (vertex_weights == 0)
    n_empty = np.sum(empty_mask)
    
    if n_empty == 0:
        return vertex_colors
    
    print(f"      ğŸ“ æ£€æµ‹åˆ° {n_empty} ä¸ªç©ºç™½é¡¶ç‚¹ï¼Œä½¿ç”¨Kè¿‘é‚»å¡«å……...")
    
    # æ‰¾åˆ°æœ‰é¢œè‰²çš„é¡¶ç‚¹
    valid_mask = (vertex_weights > 0)
    n_valid = np.sum(valid_mask)
    
    if n_valid == 0:
        print(f"      âš ï¸  æ²¡æœ‰æœ‰æ•ˆé¡¶ç‚¹ï¼Œæ— æ³•å¡«å……")
        return vertex_colors
    
    # æ„å»ºKDæ ‘ï¼ˆæ‰€æœ‰æœ‰é¢œè‰²çš„é¡¶ç‚¹ï¼‰
    valid_vertices = vertices[valid_mask]
    valid_colors = vertex_colors[valid_mask]
    kdtree = KDTree(valid_vertices)
    
    # æŸ¥è¯¢ç©ºç™½é¡¶ç‚¹çš„Kè¿‘é‚»
    empty_vertices = vertices[empty_mask]
    k_actual = min(k, n_valid)  # ç¡®ä¿kä¸è¶…è¿‡æœ‰æ•ˆé¡¶ç‚¹æ•°
    distances, indices = kdtree.query(empty_vertices, k=k_actual)
    
    # åŠ æƒå¹³å‡ï¼ˆè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§ï¼‰
    # ä½¿ç”¨åè·ç¦»åŠ æƒ (Inverse Distance Weighting)
    weights = 1.0 / (distances + 1e-6)
    weights = weights / weights.sum(axis=1, keepdims=True)
    
    # æ’å€¼é¢œè‰²
    if k_actual == 1:
        # å¦‚æœåªæœ‰1ä¸ªè¿‘é‚»ï¼Œç›´æ¥ä½¿ç”¨
        interpolated_colors = valid_colors[indices.flatten()]
    else:
        # å¤šä¸ªè¿‘é‚»ï¼ŒåŠ æƒå¹³å‡
        interpolated_colors = (valid_colors[indices] * weights[:, :, np.newaxis]).sum(axis=1)
    
    # å¡«å……
    filled_colors = vertex_colors.copy()
    filled_colors[empty_mask] = interpolated_colors
    
    print(f"      âœ“ å¡«å……å®Œæˆ")
    
    return filled_colors

# ============================================================================
# è‡ªé€‚åº”æ·±åº¦æ£€æµ‹å‡½æ•°
# ============================================================================
def adaptive_depth_test(depth_rendered, depth_measured, vertex_normals_world, 
                       up_vector=np.array([0, 0, 1]),
                       floor_normal_threshold=0.7,
                       floor_depth_front=0.3, floor_depth_back=0.08,
                       wall_depth_front=0.5, wall_depth_back=0.15,
                       min_depth=0.1, max_depth=20.0):
    """
    è‡ªé€‚åº”æ·±åº¦ä¸€è‡´æ€§æ£€æµ‹ï¼šæ ¹æ®è¡¨é¢ç±»å‹ï¼ˆåœ°é¢/å¢™å£ï¼‰å’Œæ–¹å‘ï¼ˆå‰/åï¼‰ä½¿ç”¨ä¸åŒé˜ˆå€¼
    
    å‚æ•°:
        depth_rendered: æ¸²æŸ“æ·±åº¦ï¼ˆmeshé¡¶ç‚¹åˆ°ç›¸æœºçš„è·ç¦»ï¼‰(N,)
        depth_measured: æµ‹é‡æ·±åº¦ï¼ˆdepthå›¾ä¸­çš„æ·±åº¦å€¼ï¼‰(N,)
        vertex_normals_world: ä¸–ç•Œåæ ‡ç³»ä¸‹çš„é¡¶ç‚¹æ³•å‘é‡ (N, 3)
        up_vector: ä¸–ç•Œåæ ‡ç³»çš„å‘ä¸Šæ–¹å‘ (3,)
        floor_normal_threshold: åˆ¤æ–­åœ°é¢çš„æ³•å‘é‡é˜ˆå€¼ï¼ˆcoså€¼ï¼Œé»˜è®¤0.7çº¦45Â°ï¼‰
        floor_depth_front: åœ°é¢åœ¨å‰æ—¶çš„æ·±åº¦å®¹å·®ï¼ˆç±³ï¼‰
        floor_depth_back: åœ°é¢åœ¨åæ—¶çš„æ·±åº¦å®¹å·®ï¼ˆç±³ï¼‰- ä¸¥æ ¼é˜²ç©¿é€
        wall_depth_front: å¢™å£åœ¨å‰æ—¶çš„æ·±åº¦å®¹å·®ï¼ˆç±³ï¼‰
        wall_depth_back: å¢™å£åœ¨åæ—¶çš„æ·±åº¦å®¹å·®ï¼ˆç±³ï¼‰
        min_depth: æœ€å°æœ‰æ•ˆæ·±åº¦
        max_depth: æœ€å¤§æœ‰æ•ˆæ·±åº¦
    
    è¿”å›:
        depth_consistency_mask: å¸ƒå°”æ©ç  (N,)ï¼ŒTrueè¡¨ç¤ºé€šè¿‡æ·±åº¦æ£€æµ‹
    """
    # 1. è®¡ç®—æ³•å‘é‡ä¸å‘ä¸Šæ–¹å‘çš„ç‚¹ç§¯
    up_vector_norm = up_vector / np.linalg.norm(up_vector)
    normal_dot_up = np.dot(vertex_normals_world, up_vector_norm)
    
    # 2. åˆ†ç±»è¡¨é¢ç±»å‹ï¼šåœ°é¢ vs å¢™å£
    is_floor = normal_dot_up > floor_normal_threshold
    is_wall = ~is_floor
    
    # 3. è®¡ç®—æ·±åº¦å·®å¼‚ï¼ˆå¸¦ç¬¦å·ï¼‰
    # æ­£å€¼ï¼šè¡¨é¢åœ¨depthåé¢ï¼ˆå¯èƒ½è¢«é®æŒ¡/ç©¿é€ï¼‰
    # è´Ÿå€¼ï¼šè¡¨é¢åœ¨depthå‰é¢
    depth_diff = depth_rendered - depth_measured
    is_behind = depth_diff >= 0
    
    # 4. æ ¹æ®è¡¨é¢ç±»å‹å’Œæ–¹å‘åº”ç”¨ä¸åŒé˜ˆå€¼
    depth_mask = np.zeros(len(depth_diff), dtype=bool)
    
    # åœ°é¢ï¼šåœ¨å‰æ—¶å…è®¸ä¸€å®šå®¹å·®ï¼Œåœ¨åæ—¶ä¸¥æ ¼é™åˆ¶ï¼ˆé˜²ç©¿é€æ±¡æŸ“ï¼‰
    floor_front_mask = is_floor & ~is_behind
    floor_back_mask = is_floor & is_behind
    depth_mask[floor_front_mask] = depth_diff[floor_front_mask] > -floor_depth_front
    depth_mask[floor_back_mask] = depth_diff[floor_back_mask] < floor_depth_back
    
    # å¢™å£ï¼šåœ¨å‰æ—¶è¾ƒå®½æ¾ï¼ˆé¿å…æ®‹ç¼ºï¼‰ï¼Œåœ¨åæ—¶é€‚åº¦é™åˆ¶ï¼ˆé˜²ç©¿é€ï¼‰
    wall_front_mask = is_wall & ~is_behind
    wall_back_mask = is_wall & is_behind
    depth_mask[wall_front_mask] = depth_diff[wall_front_mask] > -wall_depth_front
    depth_mask[wall_back_mask] = depth_diff[wall_back_mask] < wall_depth_back
    
    # 5. ç»“åˆæ·±åº¦èŒƒå›´æ£€æŸ¥
    depth_consistency_mask = depth_mask & (depth_measured > min_depth) & (depth_measured < max_depth)
    
    return depth_consistency_mask

# ============================================================================
# æ—‹è½¬é…ç½®ç®¡ç†å‡½æ•°
# ============================================================================
def save_rotation_config(rx, ry, rz, config_file=ROTATION_CONFIG_FILE):
    """ä¿å­˜æ—‹è½¬é…ç½®åˆ°JSONæ–‡ä»¶"""
    import json
    config = {
        'rotation': {
            'x': float(rx),
            'y': float(ry),
            'z': float(rz)
        },
        'timestamp': str(datetime.now())
    }
    config_path = Path(config_file)
    config_path.parent.mkdir(parents=True, exist_ok=True)
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"ğŸ’¾ æ—‹è½¬é…ç½®å·²ä¿å­˜åˆ°: {config_file}")

def load_rotation_config(config_file=ROTATION_CONFIG_FILE):
    """ä»JSONæ–‡ä»¶åŠ è½½æ—‹è½¬é…ç½®"""
    import json
    config_path = Path(config_file)
    if not config_path.exists():
        return None
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)
        rotation = config.get('rotation', {})
        rx = rotation.get('x', 0)
        ry = rotation.get('y', 0)
        rz = rotation.get('z', 0)
        timestamp = config.get('timestamp', 'æœªçŸ¥')
        print(f"ğŸ“‚ ä»é…ç½®æ–‡ä»¶åŠ è½½æ—‹è½¬:")
        print(f"   æ–‡ä»¶: {config_file}")
        print(f"   æ—‹è½¬: X={rx}Â°, Y={ry}Â°, Z={rz}Â°")
        print(f"   æ—¶é—´: {timestamp}")
        return (rx, ry, rz)
    except Exception as e:
        print(f"âš ï¸  åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

# ============================================================================
# ç¬¬ä¸€é˜¶æ®µï¼šåŠ è½½å¹¶éªŒè¯è½¨è¿¹
# ============================================================================
print(f"\n" + "="*70)
print(f"é˜¶æ®µ 1ï¼šè½¨è¿¹éªŒè¯")
print(f"="*70)

print(f"\n[1/3] è¯»å–é¦–å¸§ä¸–ç•Œä½å§¿")
T_world_from_first = np.eye(4, dtype=np.float32)
with open(first_pose_txt, 'r') as f:
    lines = [l.strip() for l in f if l.strip()]
    for i, line in enumerate(lines[:4]):
        vals = [float(x) for x in line.split()]
        T_world_from_first[i, :] = vals

first_position = T_world_from_first[:3, 3]
print(f"   é¦–å¸§ä¸–ç•Œä½ç½®: [{first_position[0]:.2f}, {first_position[1]:.2f}, {first_position[2]:.2f}]")

print(f"\n[2/3] è¯»å–ç›¸å¯¹ä½å§¿æ–‡ä»¶")
pose_files = sorted(Path(pose_dir).glob("*.txt"), key=lambda x: int(x.stem))
print(f"   æ‰¾åˆ° {len(pose_files)} ä¸ªä½å§¿æ–‡ä»¶")

# å­˜å‚¨ä¸–ç•Œä½å§¿
world_poses = []
world_positions = []

for i, pose_file in enumerate(pose_files):
    T_first_from_current = np.eye(4, dtype=np.float32)
    with open(pose_file, 'r') as f:
        lines = [l.strip() for l in f if l.strip()]
        for j, line in enumerate(lines[:4]):
            vals = [float(x) for x in line.split()]
            T_first_from_current[j, :] = vals
    
    T_world_from_current = T_world_from_first @ T_first_from_current
    world_poses.append(T_world_from_current)
    world_positions.append(T_world_from_current[:3, 3])

world_positions = np.array(world_positions)

# å›ºå®šæ‘„åƒå¤´é«˜åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if FIX_CAMERA_HEIGHT:
    if FIXED_HEIGHT is None:
        # ä½¿ç”¨é¦–å¸§é«˜åº¦ä½œä¸ºå›ºå®šé«˜åº¦
        fixed_z = world_positions[0, 2]
    else:
        fixed_z = FIXED_HEIGHT
    
    print(f"\n   ğŸ”’ å›ºå®šæ‘„åƒå¤´é«˜åº¦: Z = {fixed_z:.3f}")
    
    # æ›´æ–°æ‰€æœ‰ä½å§¿çš„Zåæ ‡
    for i in range(len(world_poses)):
        world_poses[i][2, 3] = fixed_z
        world_positions[i, 2] = fixed_z

# å¼ºåˆ¶ç›¸æœºæ°´å¹³ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if FORCE_CAMERA_HORIZONTAL:
    print(f"\n   ğŸ“ å¼ºåˆ¶ç›¸æœºæ°´å¹³ï¼ˆæ¶ˆé™¤rollå’Œpitchï¼‰")
    corrected_count = 0
    
    for i in range(len(world_poses)):
        # æå–å½“å‰æ—‹è½¬çŸ©é˜µ
        R_current = world_poses[i][:3, :3]
        
        # æå–yawè§’ï¼ˆç»•Zè½´çš„æ—‹è½¬ï¼‰
        # ä»æ—‹è½¬çŸ©é˜µä¸­æå–æœå‘å‘é‡ï¼ˆå‰å‘å‘é‡ï¼Œç›¸æœºçš„Zè½´æ–¹å‘ï¼‰
        forward = R_current[:, 2]  # ç›¸æœºçš„Zè½´åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„æ–¹å‘
        
        # å°†forwardå‘é‡æŠ•å½±åˆ°XYå¹³é¢ï¼ˆæ°´å¹³é¢ï¼‰
        forward_horizontal = np.array([forward[0], forward[1], 0])
        
        # å¦‚æœforwardå‡ ä¹å‚ç›´ï¼ˆforward_horizontalé•¿åº¦æ¥è¿‘0ï¼‰ï¼Œä¿æŒåŸæ ·
        if np.linalg.norm(forward_horizontal) < 1e-6:
            continue
        
        # å½’ä¸€åŒ–æ°´å¹³æœå‘
        forward_horizontal = forward_horizontal / np.linalg.norm(forward_horizontal)
        
        # æ„é€ æ–°çš„æ—‹è½¬çŸ©é˜µï¼ˆå¼ºåˆ¶æ°´å¹³ï¼‰
        # ç›¸æœºåæ ‡ç³»ï¼šXå³ï¼ŒYä¸‹ï¼ŒZå‰
        # ä¸–ç•Œåæ ‡ç³»ï¼šZä¸Š
        up_world = np.array([0, 0, 1])  # ä¸–ç•Œå‘ä¸Šæ–¹å‘
        right = np.cross(forward_horizontal, up_world)  # X = Z Ã— up
        right = right / np.linalg.norm(right)
        down = np.cross(forward_horizontal, right)  # Y = Z Ã— X
        
        # æ–°çš„æ—‹è½¬çŸ©é˜µï¼ˆåˆ—å‘é‡æ˜¯ç›¸æœºåæ ‡ç³»çš„è½´åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„è¡¨ç¤ºï¼‰
        R_new = np.column_stack([right, down, forward_horizontal])
        
        # æ›´æ–°ä½å§¿
        world_poses[i][:3, :3] = R_new
        corrected_count += 1
    
    print(f"      âœ“ å·²æ ¡æ­£ {corrected_count}/{len(world_poses)} ä¸ªä½å§¿")

print(f"   ä½å§¿ç»Ÿè®¡:")
print(f"      æ€»æ•°: {len(world_poses)}")
print(f"      XèŒƒå›´: [{world_positions[:,0].min():.2f}, {world_positions[:,0].max():.2f}]")
print(f"      YèŒƒå›´: [{world_positions[:,1].min():.2f}, {world_positions[:,1].max():.2f}]")
print(f"      ZèŒƒå›´: [{world_positions[:,2].min():.2f}, {world_positions[:,2].max():.2f}]")

print(f"\n[3/3] åŠ è½½ç½‘æ ¼")
mesh = o3d.io.read_triangle_mesh(mesh_path)
mesh.compute_vertex_normals()
vertices = np.asarray(mesh.vertices)
print(f"   é¡¶ç‚¹æ•°: {len(vertices):,}")
print(f"   ç½‘æ ¼èŒƒå›´:")
print(f"      X: [{vertices[:,0].min():.2f}, {vertices[:,0].max():.2f}]")
print(f"      Y: [{vertices[:,1].min():.2f}, {vertices[:,1].max():.2f}]")
print(f"      Z: [{vertices[:,2].min():.2f}, {vertices[:,2].max():.2f}]")

mesh.paint_uniform_color([0.8, 0.8, 0.8])

# ============================================================================
# GPU/CPUè¾…åŠ©å‡½æ•°
# ============================================================================
def to_gpu(array):
    """å°†NumPyæ•°ç»„ä¼ è¾“åˆ°GPUï¼ˆå¦‚æœå¯ç”¨GPUï¼‰"""
    if USE_GPU and array is not None:
        try:
            return cp.asarray(array)
        except Exception as e:
            print(f"âš ï¸  GPUä¼ è¾“å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            return array
    return array

def to_cpu(array):
    """å°†æ•°ç»„ä¼ å›CPUï¼ˆå¦‚æœæ˜¯GPUæ•°ç»„ï¼‰"""
    if USE_GPU and hasattr(array, 'get'):
        try:
            return cp.asnumpy(array)
        except Exception as e:
            print(f"âš ï¸  GPUä¸‹è½½å¤±è´¥: {e}")
            return array
    return array

def get_array_module(array):
    """è·å–æ•°ç»„å¯¹åº”çš„æ¨¡å—ï¼ˆnumpyæˆ–cupyï¼‰"""
    if USE_GPU and hasattr(array, 'get'):
        return cp
    return np

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if USE_GPU:
        try:
            mempool = cp.get_default_memory_pool()
            used = mempool.used_bytes() / 10243
            total = cp.cuda.Device(GPU_DEVICE_ID).mem_info[1] / 10243
            return used, total
        except:
            return 0, 0
    return 0, 0

# ============================================================================
# åˆ›å»ºè½¨è¿¹å¯è§†åŒ–å‡ ä½•ä½“
# ============================================================================
def create_arrows_for_poses(poses_list, indices):
    """åˆ›å»ºç®­å¤´å‡ ä½•ä½“"""
    arrows = []
    for idx in indices:
        T = poses_list[idx]
        position = T[:3, 3]
        z_axis = T[:3, 2]  # Zè½´æ–¹å‘ï¼ˆç›¸æœºæœå‘ï¼‰
        
        arrow = o3d.geometry.TriangleMesh.create_arrow(
            cylinder_radius=0.1 * ARROW_SCALE,
            cone_radius=0.2 * ARROW_SCALE,
            cylinder_height=1.5 * ARROW_LENGTH,
            cone_height=0.5 * ARROW_LENGTH
        )
        
        # è®¡ç®—æ—‹è½¬ï¼šä»Zè½´æ—‹è½¬åˆ°z_axisæ–¹å‘
        default_z = np.array([0, 0, 1])
        forward_normalized = z_axis / (np.linalg.norm(z_axis) + 1e-8)
        
        if np.abs(np.dot(forward_normalized, default_z)) > 0.999:
            if np.dot(forward_normalized, default_z) < 0:
                arrow_rotation = R.from_euler('x', 180, degrees=True).as_matrix()
            else:
                arrow_rotation = np.eye(3)
        else:
            v = np.cross(default_z, forward_normalized)
            s = np.linalg.norm(v)
            c = np.dot(default_z, forward_normalized)
            vx = np.array([
                [0, -v[2], v[1]],
                [v[2], 0, -v[0]],
                [-v[1], v[0], 0]
            ])
            arrow_rotation = np.eye(3) + vx + vx @ vx * ((1 - c) / (s * s + 1e-8))
        
        arrow.rotate(arrow_rotation, center=[0, 0, 0])
        arrow.translate(position)
        arrow.paint_uniform_color([0, 0.5, 1])
        arrows.append(arrow)
    return arrows

print(f"\nåˆ›å»ºè½¨è¿¹å¯è§†åŒ–...")
geometries = [mesh]

# è½¨è¿¹çº¿
trajectory_points = world_positions
trajectory_lines = [[i, i+1] for i in range(len(trajectory_points)-1)]
trajectory_lineset = o3d.geometry.LineSet()
trajectory_lineset.points = o3d.utility.Vector3dVector(trajectory_points)
trajectory_lineset.lines = o3d.utility.Vector2iVector(trajectory_lines)
trajectory_lineset.colors = o3d.utility.Vector3dVector([[0, 1, 0] for _ in trajectory_lines])
geometries.append(trajectory_lineset)

# èµ·ç‚¹æ ‡è®°
start_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
start_sphere.translate(world_positions[0])
start_sphere.paint_uniform_color([0, 1, 0])
geometries.append(start_sphere)

# ç»ˆç‚¹æ ‡è®°
end_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
end_sphere.translate(world_positions[-1])
end_sphere.paint_uniform_color([1, 0, 0])
geometries.append(end_sphere)

# æ–¹å‘ç®­å¤´
sampled_indices = list(range(0, len(world_poses), SAMPLE_RATE))
arrows = create_arrows_for_poses(world_poses, sampled_indices)
geometries.extend(arrows)

# ============================================================================
# æ—‹è½¬æ§åˆ¶å™¨ï¼ˆä» verify_trajectory_from_txt.py ç§»æ¤ï¼‰
# ============================================================================
class RotationController:
    def __init__(self, world_poses, world_positions):
        self.world_poses_original = [p.copy() for p in world_poses]
        self.world_positions_original = world_positions.copy()
        self.world_poses = world_poses
        self.world_positions = world_positions
        self.rx = self.ry = self.rz = 0
        self.rotation_center = world_positions[0].copy()
        
    def apply_rotation(self):
        rotation = R.from_euler('xyz', [self.rx, self.ry, self.rz], degrees=True).as_matrix()
        for i in range(len(self.world_poses_original)):
            T_orig = self.world_poses_original[i]
            pos_orig = T_orig[:3, 3]
            pos_new = rotation @ (pos_orig - self.rotation_center) + self.rotation_center
            rot_orig = T_orig[:3, :3]
            rot_new = rotation @ rot_orig
            self.world_poses[i][:3, :3] = rot_new
            self.world_poses[i][:3, 3] = pos_new
            self.world_positions[i] = pos_new
        print(f"\nğŸ”„ åº”ç”¨æ—‹è½¬: X={self.rx}Â°, Y={self.ry}Â°, Z={self.rz}Â°")
        return True
    
    def rotate_x(self, degrees):
        self.rx = (self.rx + degrees) % 360
        return self.apply_rotation()
    
    def rotate_y(self, degrees):
        self.ry = (self.ry + degrees) % 360
        return self.apply_rotation()
    
    def rotate_z(self, degrees):
        self.rz = (self.rz + degrees) % 360
        return self.apply_rotation()
    
    def reset(self):
        self.rx = self.ry = self.rz = 0
        for i in range(len(self.world_poses_original)):
            self.world_poses[i][:] = self.world_poses_original[i]
            self.world_positions[i][:] = self.world_positions_original[i]
        print(f"\nğŸ”„ é‡ç½®æ—‹è½¬")
        return True

class OrientationController:
    def __init__(self, world_poses):
        self.world_poses = world_poses
        self.orientation_base = [pose[:3, :3].copy() for pose in world_poses]
        self.ox = self.oy = self.oz = 0
        self.enabled = False
        
    def lock_positions(self):
        self.orientation_base = [pose[:3, :3].copy() for pose in self.world_poses]
        self.ox = self.oy = self.oz = 0
        self.enabled = True
        print(f"\nğŸ”’ å·²é”å®šåæ ‡ä½ç½®ï¼Œè¿›å…¥æœå‘è°ƒæ•´æ¨¡å¼")
        return True
    
    def apply_orientation_rotation(self):
        if not self.enabled:
            print(f"âš ï¸  è¯·å…ˆæŒ‰ [L] é”å®šåæ ‡ä½ç½®")
            return False
        
        rx_rad = np.radians(self.ox)
        ry_rad = np.radians(self.oy)
        rz_rad = np.radians(self.oz)
        
        Rx = np.array([
            [1, 0, 0],
            [0, np.cos(rx_rad), -np.sin(rx_rad)],
            [0, np.sin(rx_rad), np.cos(rx_rad)]
        ])
        Ry = np.array([
            [np.cos(ry_rad), 0, np.sin(ry_rad)],
            [0, 1, 0],
            [-np.sin(ry_rad), 0, np.cos(ry_rad)]
        ])
        Rz = np.array([
            [np.cos(rz_rad), -np.sin(rz_rad), 0],
            [np.sin(rz_rad), np.cos(rz_rad), 0],
            [0, 0, 1]
        ])
        
        rotation = Rz @ Ry @ Rx
        for i in range(len(self.world_poses)):
            rot_base = self.orientation_base[i]
            rot_new = rotation @ rot_base
            self.world_poses[i][:3, :3] = rot_new
        
        print(f"\nğŸ”„ åº”ç”¨æœå‘æ—‹è½¬: X={self.ox}Â°, Y={self.oy}Â°, Z={self.oz}Â°")
        return True
    
    def rotate_orientation_x(self, degrees):
        if not self.enabled:
            print(f"âš ï¸  è¯·å…ˆæŒ‰ [L] é”å®šåæ ‡ä½ç½®")
            return False
        self.ox = (self.ox + degrees) % 360
        return self.apply_orientation_rotation()
    
    def rotate_orientation_y(self, degrees):
        if not self.enabled:
            print(f"âš ï¸  è¯·å…ˆæŒ‰ [L] é”å®šåæ ‡ä½ç½®")
            return False
        self.oy = (self.oy + degrees) % 360
        return self.apply_orientation_rotation()
    
    def rotate_orientation_z(self, degrees):
        if not self.enabled:
            print(f"âš ï¸  è¯·å…ˆæŒ‰ [L] é”å®šåæ ‡ä½ç½®")
            return False
        self.oz = (self.oz + degrees) % 360
        return self.apply_orientation_rotation()
    
    def reset_orientation(self):
        if not self.enabled:
            print(f"âš ï¸  è¯·å…ˆæŒ‰ [L] é”å®šåæ ‡ä½ç½®")
            return False
        self.ox = self.oy = self.oz = 0
        for i in range(len(self.world_poses)):
            self.world_poses[i][:3, :3] = self.orientation_base[i]
        print(f"\nğŸ”„ é‡ç½®æœå‘")
        return True

rotation_controller = RotationController(world_poses, world_positions)
orientation_controller = OrientationController(world_poses)

# ============================================================================
# å¯è§†åŒ–æ›´æ–°å‡½æ•°
# ============================================================================
def update_all_geometries_on_vis_thread(vis):
    """æ›´æ–°å‡ ä½•ä½“"""
    # æ›´æ–°è½¨è¿¹çº¿
    trajectory_points = rotation_controller.world_positions
    trajectory_lineset.points = o3d.utility.Vector3dVector(trajectory_points)
    vis.update_geometry(trajectory_lineset)
    
    # æ›´æ–°èµ·ç‚¹çƒ
    start_sphere.clear()
    start_sphere_temp = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
    start_sphere_temp.translate(rotation_controller.world_positions[0])
    start_sphere_temp.paint_uniform_color([0, 1, 0])
    start_sphere.vertices = start_sphere_temp.vertices
    start_sphere.triangles = start_sphere_temp.triangles
    start_sphere.vertex_colors = start_sphere_temp.vertex_colors
    vis.update_geometry(start_sphere)
    
    # æ›´æ–°ç»ˆç‚¹çƒ
    end_sphere.clear()
    end_sphere_temp = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
    end_sphere_temp.translate(rotation_controller.world_positions[-1])
    end_sphere_temp.paint_uniform_color([1, 0, 0])
    end_sphere.vertices = end_sphere_temp.vertices
    end_sphere.triangles = end_sphere_temp.triangles
    end_sphere.vertex_colors = end_sphere_temp.vertex_colors
    vis.update_geometry(end_sphere)
    
    # æ›´æ–°ç®­å¤´
    arrow_geometries = geometries[4:]
    for i, idx in enumerate(sampled_indices):
        if i < len(arrow_geometries):
            arrow = arrow_geometries[i]
            arrow.clear()
            
            pose = rotation_controller.world_poses[idx]
            position = pose[:3, 3]
            z_axis = pose[:3, 2]
            
            arrow_temp = o3d.geometry.TriangleMesh.create_arrow(
                cylinder_radius=0.1 * ARROW_SCALE,
                cone_radius=0.2 * ARROW_SCALE,
                cylinder_height=1.5 * ARROW_LENGTH,
                cone_height=0.5 * ARROW_LENGTH
            )
            
            default_z = np.array([0, 0, 1])
            forward_normalized = z_axis / (np.linalg.norm(z_axis) + 1e-8)
            
            if np.abs(np.dot(forward_normalized, default_z)) > 0.999:
                if np.dot(forward_normalized, default_z) < 0:
                    arrow_rotation = R.from_euler('x', 180, degrees=True).as_matrix()
                else:
                    arrow_rotation = np.eye(3)
            else:
                v = np.cross(default_z, forward_normalized)
                s = np.linalg.norm(v)
                c = np.dot(default_z, forward_normalized)
                vx = np.array([
                    [0, -v[2], v[1]],
                    [v[2], 0, -v[0]],
                    [-v[1], v[0], 0]
                ])
                arrow_rotation = np.eye(3) + vx + vx @ vx * ((1 - c) / (s * s + 1e-8))
            
            arrow_temp.rotate(arrow_rotation, center=[0, 0, 0])
            arrow_temp.translate(position)
            arrow_temp.paint_uniform_color([0, 0.5, 1])
            
            arrow.vertices = arrow_temp.vertices
            arrow.triangles = arrow_temp.triangles
            arrow.vertex_colors = arrow_temp.vertex_colors
            vis.update_geometry(arrow)
    
    vis.update_renderer()

# ============================================================================
# å¯åŠ¨è½¨è¿¹éªŒè¯çª—å£
# ============================================================================
print(f"\n" + "="*70)
print(f"å¯åŠ¨è½¨è¿¹éªŒè¯çª—å£...")
print(f"="*70)

# æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„é…ç½®
saved_config = load_rotation_config() if AUTO_LOAD_ROTATION else None
if saved_config:
    print(f"\nğŸ’¡ æç¤º: æ£€æµ‹åˆ°å·²ä¿å­˜çš„æ—‹è½¬é…ç½®ï¼Œå¯åŠ¨åå¯ç›´æ¥ä½¿ç”¨")

print(f"\nğŸ® ç¬¬ä¸€é˜¶æ®µï¼šåæ ‡ä½ç½®æ—‹è½¬")
print(f"  [1/2] ç»•Xè½´: +90Â° / -90Â°")
print(f"  [3/4] ç»•Yè½´: +90Â° / -90Â°")
print(f"  [5/6] ç»•Zè½´: +90Â° / -90Â°")
print(f"  [R]   é‡ç½®æ—‹è½¬")
print(f"\nğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šç›¸æœºæœå‘è°ƒæ•´")
print(f"  [L]   é”å®šåæ ‡ä½ç½®")
print(f"  [7/8] æœå‘Xè½´: +90Â° / -90Â°")
print(f"  [9/0] æœå‘Yè½´: +90Â° / -90Â°")
print(f"  [U/I] æœå‘Zè½´: +90Â° / -90Â°")
print(f"  [O]   é‡ç½®æœå‘")
print(f"\nğŸ’¾ é…ç½®ç®¡ç†:")
print(f"  [S]     ä¿å­˜å½“å‰æ—‹è½¬é…ç½®")
print(f"  [ENTER] ä¿å­˜é…ç½®å¹¶å¼€å§‹çº¹ç†åŒ–")
print(f"\nåŸºæœ¬æ“ä½œ:")
print(f"  - é¼ æ ‡æ‹–åŠ¨: æ—‹è½¬è§†è§’")
print(f"  - æ»šè½®: ç¼©æ”¾")
print(f"  - Q/ESC: é€€å‡º\n")

vis = o3d.visualization.Visualizer()
vis.create_window(window_name="è½¨è¿¹éªŒè¯ - æŒ‰ENTERç¡®è®¤åå¼€å§‹çº¹ç†åŒ–", width=1600, height=900)

for geom in geometries:
    vis.add_geometry(geom)

render_option = vis.get_render_option()
render_option.mesh_show_back_face = True
render_option.light_on = True

# å‘½ä»¤é˜Ÿåˆ—
command_queue = deque()
queue_lock = threading.Lock()
should_quit = [False]
start_texturing = [False]

def enqueue_command(cmd: str):
    with queue_lock:
        command_queue.append(cmd)

def dequeue_commands():
    with queue_lock:
        items = list(command_queue)
        command_queue.clear()
        return items

# é”®ç›˜æ˜ å°„
key_to_action = {
    ord('1'): lambda: rotation_controller.rotate_x(90),
    ord('2'): lambda: rotation_controller.rotate_x(-90),
    ord('3'): lambda: rotation_controller.rotate_y(90),
    ord('4'): lambda: rotation_controller.rotate_y(-90),
    ord('5'): lambda: rotation_controller.rotate_z(90),
    ord('6'): lambda: rotation_controller.rotate_z(-90),
    ord('R'): lambda: rotation_controller.reset(),
    ord('r'): lambda: rotation_controller.reset(),
    ord('L'): lambda: orientation_controller.lock_positions(),
    ord('l'): lambda: orientation_controller.lock_positions(),
    ord('7'): lambda: orientation_controller.rotate_orientation_x(90),
    ord('8'): lambda: orientation_controller.rotate_orientation_x(-90),
    ord('9'): lambda: orientation_controller.rotate_orientation_y(90),
    ord('0'): lambda: orientation_controller.rotate_orientation_y(-90),
    ord('U'): lambda: orientation_controller.rotate_orientation_z(90),
    ord('u'): lambda: orientation_controller.rotate_orientation_z(90),
    ord('I'): lambda: orientation_controller.rotate_orientation_z(-90),
    ord('i'): lambda: orientation_controller.rotate_orientation_z(-90),
    ord('O'): lambda: orientation_controller.reset_orientation(),
    ord('o'): lambda: orientation_controller.reset_orientation(),
}

def animation_callback(vis):
    if should_quit[0] or start_texturing[0]:
        return False

    cmds = dequeue_commands()
    if not cmds:
        return True

    updated = False
    for cmd in cmds:
        if cmd in ('Q', 'QUIT', 'EXIT'):
            print("é€€å‡º...")
            should_quit[0] = True
            return False
        elif cmd == 'START':
            print("\nâœ… è½¨è¿¹ç¡®è®¤ï¼Œå‡†å¤‡å¼€å§‹çº¹ç†åŒ–...")
            start_texturing[0] = True
            return False
        
        for ch in cmd:
            key_code = ord(ch)
            if key_code in key_to_action:
                result = key_to_action[key_code]()
                if result:
                    updated = True

    if updated:
        update_all_geometries_on_vis_thread(vis)

    return True

vis.register_animation_callback(animation_callback)

def input_thread_func():
    try:
        import os
        import time
        
        # æ£€æŸ¥æ˜¯å¦è‡ªåŠ¨æ¨¡å¼
        auto_mode = os.environ.get('AUTO_TEXTURE', '').lower() == 'true'
        
        # å°è¯•åŠ è½½å·²ä¿å­˜çš„æ—‹è½¬é…ç½®
        loaded_rotation = None
        if AUTO_LOAD_ROTATION and not auto_mode:
            loaded_rotation = load_rotation_config()
        
        if auto_mode:
            # è‡ªåŠ¨æ¨¡å¼ï¼šåº”ç”¨é»˜è®¤æ—‹è½¬å¹¶å¼€å§‹
            print("\nğŸ¤– è‡ªåŠ¨æ¨¡å¼ï¼šåº”ç”¨é»˜è®¤æ—‹è½¬å¹¶å¼€å§‹")
            rx, ry, rz = DEFAULT_ROTATION
            # åº”ç”¨æ—‹è½¬
            for _ in range(int(rx // 90)):
                enqueue_command('1')
                time.sleep(0.3)
            for _ in range(int(ry // 90)):
                enqueue_command('3')
                time.sleep(0.3)
            for _ in range(int(rz // 90)):
                enqueue_command('5')
                time.sleep(0.3)
            time.sleep(0.5)
            enqueue_command('START')
            # ä¿å­˜é…ç½®
            save_rotation_config(rx, ry, rz)
            return
        
        elif loaded_rotation is not None:
            # è‡ªåŠ¨åŠ è½½æ¨¡å¼ï¼šä½¿ç”¨å·²ä¿å­˜çš„é…ç½®
            rx, ry, rz = loaded_rotation
            print(f"\nâœ… ä½¿ç”¨å·²ä¿å­˜çš„æ—‹è½¬é…ç½®")
            print(f"   æŒ‰ [Y] åº”ç”¨å¹¶å¼€å§‹ / [N] æ‰‹åŠ¨è°ƒæ•´ / [D] åˆ é™¤é…ç½®")
            response = input("   ä½ çš„é€‰æ‹©: ").strip().upper()
            
            if response == 'Y':
                # åº”ç”¨å·²ä¿å­˜çš„æ—‹è½¬
                print(f"\nğŸ”„ åº”ç”¨æ—‹è½¬: X={rx}Â°, Y={ry}Â°, Z={rz}Â°")
                for _ in range(int(rx // 90)):
                    enqueue_command('1')
                    time.sleep(0.3)
                for _ in range(int(ry // 90)):
                    enqueue_command('3')
                    time.sleep(0.3)
                for _ in range(int(rz // 90)):
                    enqueue_command('5')
                    time.sleep(0.3)
                time.sleep(0.5)
                enqueue_command('START')
                return
            elif response == 'D':
                # åˆ é™¤é…ç½®æ–‡ä»¶
                try:
                    Path(ROTATION_CONFIG_FILE).unlink()
                    print(f"ğŸ—‘ï¸  é…ç½®æ–‡ä»¶å·²åˆ é™¤")
                except:
                    pass
                # ç»§ç»­æ‰‹åŠ¨è°ƒæ•´
            else:
                print(f"ğŸ® è¿›å…¥æ‰‹åŠ¨è°ƒæ•´æ¨¡å¼")
        
        # æ‰‹åŠ¨è°ƒæ•´æ¨¡å¼
        while not should_quit[0] and not start_texturing[0]:
            print(f"\n[æ—‹è½¬: X={rotation_controller.rx}Â° Y={rotation_controller.ry}Â° Z={rotation_controller.rz}Â°] ", end="")
            print("è¾“å…¥å‘½ä»¤ (1-6æ—‹è½¬, Lé”å®š, Sä¿å­˜é…ç½®, ENTERå¼€å§‹çº¹ç†åŒ–, Qé€€å‡º): ", end="", flush=True)
            cmd = input().strip().upper()
            if not cmd:
                # Enteré”®ï¼šä¿å­˜é…ç½®å¹¶å¼€å§‹çº¹ç†åŒ–
                save_rotation_config(rotation_controller.rx, rotation_controller.ry, rotation_controller.rz)
                enqueue_command('START')
                break
            elif cmd == 'S':
                # æ‰‹åŠ¨ä¿å­˜é…ç½®
                save_rotation_config(rotation_controller.rx, rotation_controller.ry, rotation_controller.rz)
                continue
            enqueue_command(cmd)
            if cmd in ('Q', 'QUIT', 'EXIT'):
                break
    except (KeyboardInterrupt, EOFError):
        enqueue_command('Q')

input_thread = threading.Thread(target=input_thread_func, daemon=True)
input_thread.start()

vis.run()
vis.destroy_window()

if should_quit[0]:
    print("\nç”¨æˆ·å–æ¶ˆï¼Œç¨‹åºé€€å‡º")
    sys.exit(0)

# ============================================================================
# ç¬¬äºŒé˜¶æ®µï¼šå®æ—¶çº¹ç†åŒ–
# ============================================================================
print(f"\n" + "="*70)
print(f"é˜¶æ®µ 2ï¼šå®æ—¶çº¹ç†åŒ–")
print(f"="*70)

# ä½¿ç”¨ç¡®è®¤åçš„ä½å§¿
camera_poses_Twc = world_poses  # å·²ç»æ˜¯ Twc æ ¼å¼ï¼ˆworld -> cam çš„é€†ï¼‰
camera_positions = world_positions

# ä¿å­˜æ—‹è½¬å‚æ•°ï¼ˆç”¨äºè‡ªé€‚åº”æ·±åº¦æ£€æµ‹ï¼‰
final_rx = rotation_controller.rx
final_ry = rotation_controller.ry
final_rz = rotation_controller.rz

# åŠ è½½å†…å‚
print(f"\n[1/3] åŠ è½½ç›¸æœºå†…å‚")
K_data = np.load(K_npz)
K = K_data['K']
if 'W' in K_data and 'H' in K_data:
    W, H = int(K_data['W']), int(K_data['H'])
elif 'width' in K_data and 'height' in K_data:
    W, H = int(K_data['width']), int(K_data['height'])
else:
    raise KeyError("ç›¸æœºå†…å‚æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'W/H' æˆ– 'width/height' é”®")
print(f"   å›¾åƒå°ºå¯¸: {W}x{H}")

# é‡‡æ ·
frame_ids = np.arange(len(camera_poses_Twc))
texture_sampled_indices = list(range(0, len(frame_ids), FRAME_SAMPLE_RATE))[:MAX_IMAGES]
sampled_positions = camera_positions[texture_sampled_indices]
sampled_frame_ids = [frame_ids[i] for i in texture_sampled_indices]
sampled_Twc = [camera_poses_Twc[i] for i in texture_sampled_indices]
sampled_Tcw = [np.linalg.inv(T) for T in sampled_Twc]

print(f"   é‡‡æ ·: {len(texture_sampled_indices)} å¸§")

# åˆå§‹åŒ–OpenMVSå¢å¼ºåŠŸèƒ½
print(f"\n[2/3] åˆå§‹åŒ–OpenMVSå¢å¼ºåŠŸèƒ½")
vertices_np = np.asarray(mesh.vertices)
normals_np = np.asarray(mesh.vertex_normals)
vertex_colors = np.zeros((len(vertices_np), 3))
vertex_weights = np.zeros(len(vertices_np))
frame_exposures = []
initial_colors = np.full((len(vertices_np), 3), 0.3)
mesh.vertex_colors = o3d.utility.Vector3dVector(initial_colors)

# ä¸Šä¼ å¸¸ç”¨æ•°æ®åˆ°GPU
vertex_colors_gpu = None
vertex_weights_gpu = None
if USE_GPU:
    print(f"\n   ğŸ“¤ ä¸Šä¼ æ•°æ®åˆ°GPU...")
    vertices_gpu = to_gpu(vertices_np)
    normals_gpu = to_gpu(normals_np)
    K_gpu = to_gpu(K)
    print(f"      âœ“ é¡¶ç‚¹: {len(vertices_np):,}")
    print(f"      âœ“ æ³•å‘é‡: {len(normals_np):,}")
    print(f"      âœ“ ç›¸æœºå†…å‚: {K.shape}")
    mem_used, mem_total = check_gpu_memory()
    print(f"      æ˜¾å­˜ä½¿ç”¨: {mem_used:.2f} / {mem_total:.1f} GB")
else:
    vertices_gpu = vertices_np
    normals_gpu = normals_np
    K_gpu = K

# ç›¸æœºå¯è§†åŒ–è¾…åŠ©å‡½æ•°
def create_camera_frustum(T_wc, scale=0.5):
    frustum_cam = np.array([
        [ 0.0,  0.0,  0.0],
        [-0.5, -0.3,  1.0],
        [ 0.5, -0.3,  1.0],
        [ 0.5,  0.3,  1.0],
        [-0.5,  0.3,  1.0],
    ]) * scale
    frustum_h = np.hstack([frustum_cam, np.ones((frustum_cam.shape[0], 1))])
    frustum_world = (T_wc @ frustum_h.T).T[:, :3]
    lines = [[0,1],[0,2],[0,3],[0,4],[1,2],[2,3],[3,4],[4,1]]
    ls = o3d.geometry.LineSet()
    ls.points = o3d.utility.Vector3dVector(frustum_world)
    ls.lines  = o3d.utility.Vector2iVector(lines)
    ls.colors = o3d.utility.Vector3dVector([[1,0,0]]*len(lines))
    return ls

def create_camera_coordinate_frame(T_wc, scale=0.3):
    cam_pos = T_wc[:3, 3]
    Rw = T_wc[:3, :3]
    points_list = []
    lines_list = []
    colors_list = []

    def add_axis(dir_cam, color_rgb, n_seg=5):
        nonlocal points_list, lines_list, colors_list
        start_idx = len(points_list)
        for i in range(n_seg):
            t = i / float(n_seg)
            p = cam_pos + Rw @ (dir_cam * (scale * t))
            points_list.append(p)
        points_list.append(cam_pos + Rw @ (dir_cam * scale))
        for i in range(n_seg):
            lines_list.append([start_idx + i, start_idx + i + 1])
            colors_list.append(color_rgb)

    add_axis(np.array([1.0, 0.0, 0.0]), [1, 0, 0])  # X - çº¢è‰²
    add_axis(np.array([0.0, 1.0, 0.0]), [0, 1, 0])  # Y - ç»¿è‰²
    add_axis(np.array([0.0, 0.0, 1.0]), [0, 0.5, 1])  # Z - è“è‰²

    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(np.array(points_list))
    line_set.lines = o3d.utility.Vector2iVector(lines_list)
    line_set.colors = o3d.utility.Vector3dVector(np.array(colors_list))
    return line_set

# å¯åŠ¨å¯è§†åŒ–
print(f"\n[3/3] å¯åŠ¨å®æ—¶å¯è§†åŒ–")
print(f"\nå¼€å§‹çº¹ç†åŒ–...")

vis2 = o3d.visualization.Visualizer()
vis2.create_window(window_name="å®æ—¶çº¹ç†åŒ– - OpenMVSå¢å¼ºç‰ˆ", width=1600, height=900)
vis2.add_geometry(mesh)

start_sphere2 = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
start_sphere2.translate(camera_positions[0])
start_sphere2.paint_uniform_color([0, 1, 0])
vis2.add_geometry(start_sphere2)

current_camera_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
current_camera_sphere.paint_uniform_color([1, 0, 0])
vis2.add_geometry(current_camera_sphere)

current_frustum = o3d.geometry.LineSet()
vis2.add_geometry(current_frustum)

current_frame = o3d.geometry.LineSet()
vis2.add_geometry(current_frame)

processed_trajectory = o3d.geometry.LineSet()
vis2.add_geometry(processed_trajectory)

history_frames = []
for _ in range(20):
    frame = o3d.geometry.LineSet()
    vis2.add_geometry(frame)
    history_frames.append(frame)

render_option2 = vis2.get_render_option()
render_option2.mesh_show_back_face = True
render_option2.light_on = True

# ============================================================================
# ä¸»å¾ªç¯ - OpenMVSå¢å¼ºçº¹ç†åŒ–
# ============================================================================
print(f"\n{'='*70}")
print(f"å¼€å§‹çº¹ç†åŒ–å¤„ç†")
print(f"{'='*70}")
if USE_GPU:
    mem_used, mem_total = check_gpu_memory()
    print(f"ğŸš€ è¿è¡Œæ¨¡å¼: GPUåŠ é€Ÿ")
    # è·å–GPUåç§°ï¼ˆå…¼å®¹ä¸åŒCuPyç‰ˆæœ¬ï¼‰
    try:
        device = cp.cuda.Device(GPU_DEVICE_ID)
        gpu_name = device.attributes.get('Name', b'GPU Device')
        if isinstance(gpu_name, bytes):
            gpu_name = gpu_name.decode()
        print(f"   GPUè®¾å¤‡: {gpu_name}")
    except:
        print(f"   GPUè®¾å¤‡: Device {GPU_DEVICE_ID}")
    print(f"   åˆå§‹æ˜¾å­˜: {mem_used:.2f} / {mem_total:.1f} GB")
else:
    print(f"ğŸ’» è¿è¡Œæ¨¡å¼: CPU")
print(f"   æ€»å¸§æ•°: {len(texture_sampled_indices)}")
print(f"   é‡‡æ ·ç‡: æ¯{FRAME_SAMPLE_RATE}å¸§")
print(f"{'='*70}")
print(f"\nå¤„ç†å¸§...")

frame_count = 0
history_count = 0
start_time = time.time()

# å›¾åƒè´¨é‡ç»Ÿè®¡
quality_stats = {
    'total_frames': 0,
    'skipped_blur': 0,
    'skipped_overexp': 0,
    'skipped_underexp': 0,
    'skipped_quality': 0,
    'processed_frames': 0,
    'avg_quality': [],
    'avg_sharpness': []
}

for i in range(len(texture_sampled_indices)):
    if not vis2.poll_events():
        break

    fid = sampled_frame_ids[i]
    rgb_file = Path(rgb_dir) / f"{fid}.png"
    if not rgb_file.exists():
        rgb_file = Path(rgb_dir) / f"{fid:04d}.png"
    
    depth_file = Path(depth_dir) / f"{fid}.png"
    if not depth_file.exists():
        depth_file = Path(depth_dir) / f"{fid:04d}.png"

    if not rgb_file.exists():
        print(f"\n   è­¦å‘Š: RGBæ–‡ä»¶ä¸å­˜åœ¨: {rgb_file}")
        continue

    rgb_img = cv2.imread(str(rgb_file))
    if rgb_img is None:
        continue
    rgb_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2RGB) / 255.0

    # ========================================================================
    # å›¾åƒé¢„å¤„ç†å¢å¼ºï¼ˆç¬¬2æ­¥ä¼˜åŒ–ï¼‰- åœ¨è´¨é‡è¯„ä¼°ä¹‹å‰åº”ç”¨
    # ========================================================================
    if USE_IMAGE_ENHANCEMENT:
        rgb_img = enhance_image(rgb_img)

    # ========================================================================
    # å›¾åƒè´¨é‡è¯„ä¼°ä¸è¿‡æ»¤ï¼ˆç¬¬1æ­¥ä¼˜åŒ–ï¼‰
    # ========================================================================
    if USE_IMAGE_QUALITY_FILTER:
        quality_stats['total_frames'] += 1
        quality_score, sharpness, overexposed, underexposed, contrast = assess_image_quality(rgb_img)
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è´¨é‡æ ‡å‡†
        quality_passed = True
        skip_reasons = []
        
        if quality_score < IMAGE_QUALITY_THRESHOLD:
            quality_passed = False
            skip_reasons.append(f"è´¨é‡åˆ†={quality_score:.1f}<{IMAGE_QUALITY_THRESHOLD:.1f}")
            quality_stats['skipped_quality'] += 1
        
        if sharpness < SHARPNESS_THRESHOLD:
            quality_passed = False
            skip_reasons.append(f"æ¨¡ç³Š(æ¸…æ™°åº¦={sharpness:.1f}<{SHARPNESS_THRESHOLD:.1f})")
            quality_stats['skipped_blur'] += 1
        
        if overexposed > MAX_OVEREXPOSURE:
            quality_passed = False
            skip_reasons.append(f"è¿‡æ›({overexposed*100:.1f}%>{MAX_OVEREXPOSURE*100:.1f}%)")
            quality_stats['skipped_overexp'] += 1
        
        if underexposed > MAX_UNDEREXPOSURE:
            quality_passed = False
            skip_reasons.append(f"æ¬ æ›({underexposed*100:.1f}%>{MAX_UNDEREXPOSURE*100:.1f}%)")
            quality_stats['skipped_underexp'] += 1
        
        # å¦‚æœè´¨é‡ä¸åˆæ ¼ï¼Œè·³è¿‡æ­¤å¸§
        if not quality_passed:
            if SHOW_QUALITY_STATS:
                reasons_str = ", ".join(skip_reasons)
                print(f"   [è·³è¿‡å¸§{fid:04d}] {reasons_str}")
            continue
        
        # è®°å½•é€šè¿‡çš„å¸§çš„è´¨é‡æŒ‡æ ‡
        quality_stats['processed_frames'] += 1
        quality_stats['avg_quality'].append(quality_score)
        quality_stats['avg_sharpness'].append(sharpness)
        
        # æ˜¾ç¤ºè´¨é‡ç»Ÿè®¡ï¼ˆä»…å¯¹é€šè¿‡çš„å¸§ï¼‰
        if SHOW_QUALITY_STATS and frame_count % 50 == 0:  # æ¯50å¸§æ˜¾ç¤ºä¸€æ¬¡
            print(f"   [å¸§{fid:04d}] è´¨é‡={quality_score:.1f}, æ¸…æ™°åº¦={sharpness:.1f}, "
                  f"è¿‡æ›={overexposed*100:.1f}%, æ¬ æ›={underexposed*100:.1f}%, å¯¹æ¯”åº¦={contrast:.1f}")

    depth_img = None
    if USE_DEPTH_CONSISTENCY and depth_file.exists():
        depth_img = cv2.imread(str(depth_file), cv2.IMREAD_UNCHANGED)
        if depth_img is not None:
            depth_img = depth_img.astype(np.float32) / DEPTH_SCALE

    if USE_EXPOSURE_COMP:
        frame_brightness = np.mean(rgb_img)
        frame_exposures.append(frame_brightness)
        if len(frame_exposures) > 1:
            avg_brightness = np.mean(frame_exposures)
            exposure_factor = avg_brightness / (frame_brightness + 1e-6)
            rgb_img = np.clip(rgb_img * exposure_factor, 0, 1)

    T_wc_use = sampled_Twc[i]
    T_cw_use = sampled_Tcw[i]
    cam_pos = T_wc_use[:3, 3]

    # æ›´æ–°å¯è§†åŒ–
    sphere_center = np.asarray(current_camera_sphere.get_center())
    current_camera_sphere.translate(cam_pos - sphere_center)
    vis2.update_geometry(current_camera_sphere)

    if SHOW_CAMERA_FRUSTUM:
        new_frustum = create_camera_frustum(T_wc_use, scale=2.0)
        current_frustum.points = new_frustum.points
        current_frustum.lines = new_frustum.lines
        current_frustum.colors = new_frustum.colors
        vis2.update_geometry(current_frustum)

    new_frame = create_camera_coordinate_frame(T_wc_use, scale=1.5)
    current_frame.points = new_frame.points
    current_frame.lines = new_frame.lines
    current_frame.colors = new_frame.colors
    vis2.update_geometry(current_frame)

    if i % 5 == 0 and history_count < len(history_frames):
        history_frame = create_camera_coordinate_frame(T_wc_use, scale=0.8)
        history_frames[history_count].points = history_frame.points
        history_frames[history_count].lines = history_frame.lines
        history_colors = np.array(history_frame.colors) * 0.5
        history_frames[history_count].colors = o3d.utility.Vector3dVector(history_colors)
        vis2.update_geometry(history_frames[history_count])
        history_count += 1

    if i > 0:
        trajectory_points = sampled_positions[:i+1]
        trajectory_lines = [[j, j+1] for j in range(len(trajectory_points)-1)]
        processed_trajectory.points = o3d.utility.Vector3dVector(trajectory_points)
        processed_trajectory.lines = o3d.utility.Vector2iVector(trajectory_lines)
        processed_trajectory.colors = o3d.utility.Vector3dVector([[0, 1, 0] for _ in trajectory_lines])
        vis2.update_geometry(processed_trajectory)

    # OpenMVSå¢å¼ºçº¹ç†æ˜ å°„
    if USE_GPU:
        # GPUåŠ é€Ÿç‰ˆæœ¬ - æ›´å¤šæ“ä½œåœ¨GPUä¸Šå®Œæˆ
        xp = cp
        T_cw_gpu = to_gpu(T_cw_use)
        
        # é¡¶ç‚¹å˜æ¢åˆ°ç›¸æœºåæ ‡ç³»ï¼ˆGPUï¼‰
        ones_gpu = xp.ones((len(vertices_gpu), 1), dtype=xp.float32)
        vertices_hom_gpu = xp.hstack([vertices_gpu, ones_gpu])
        vertices_cam_gpu = (T_cw_gpu @ vertices_hom_gpu.T).T
        visible_mask_gpu = vertices_cam_gpu[:, 2] > MIN_DEPTH
        
        if xp.any(visible_mask_gpu):
            # æŠ•å½±è®¡ç®—ï¼ˆGPUï¼‰
            vertices_cam_vis_gpu = vertices_cam_gpu[visible_mask_gpu, :3]
            
            # ç¬¬7æ­¥ä¼˜åŒ–ï¼šä½¿ç”¨äºšåƒç´ ç²¾åº¦æŠ•å½±ï¼ˆGPUç‰ˆæœ¬ï¼‰
            if USE_SUBPIXEL_PRECISION:
                u_f_gpu, v_f_gpu = project_vertices_subpixel_gpu(
                    vertices_cam_vis_gpu, K_gpu, H, W, use_float64=USE_FLOAT64_PROJECTION
                )
            else:
                # ä¼ ç»ŸæŠ•å½±ï¼ˆfloat32ï¼‰
                points_2d_gpu = K_gpu @ vertices_cam_vis_gpu.T
                u_f_gpu = points_2d_gpu[0, :] / points_2d_gpu[2, :]
                v_f_gpu = points_2d_gpu[1, :] / points_2d_gpu[2, :]
                v_f_gpu = H - 1 - v_f_gpu
            
            # è¾¹ç•Œæ£€æŸ¥ï¼ˆGPUï¼‰
            in_bounds_gpu = (u_f_gpu >= 0.5) & (u_f_gpu < W-0.5) & (v_f_gpu >= 0.5) & (v_f_gpu < H-0.5)
            
            # åªä¼ è¾“å¿…è¦çš„æ•°æ®åˆ°CPU
            if xp.any(in_bounds_gpu):
                visible_mask = to_cpu(visible_mask_gpu)
                in_bounds = to_cpu(in_bounds_gpu)
                u_f = to_cpu(u_f_gpu[in_bounds_gpu])
                v_f = to_cpu(v_f_gpu[in_bounds_gpu])
                vertices_cam_vis = to_cpu(vertices_cam_vis_gpu)
            else:
                visible_mask = to_cpu(visible_mask_gpu)
                in_bounds = np.array([])
                u_f = np.array([])
                v_f = np.array([])
                vertices_cam_vis = to_cpu(vertices_cam_vis_gpu)
        else:
            visible_mask = to_cpu(visible_mask_gpu)
            in_bounds = np.array([])
            u_f = np.array([])
            v_f = np.array([])
            vertices_cam_vis = np.array([])
    else:
        # CPUç‰ˆæœ¬
        vertices_hom = np.hstack([vertices_np, np.ones((len(vertices_np), 1))])
        vertices_cam = (T_cw_use @ vertices_hom.T).T
        visible_mask = vertices_cam[:, 2] > MIN_DEPTH
        
        if np.any(visible_mask):
            vertices_cam_vis = vertices_cam[visible_mask, :3]
            
            # ç¬¬7æ­¥ä¼˜åŒ–ï¼šä½¿ç”¨äºšåƒç´ ç²¾åº¦æŠ•å½±
            if USE_SUBPIXEL_PRECISION:
                u_f, v_f = project_vertices_subpixel(
                    vertices_cam_vis, K, H, W, use_float64=USE_FLOAT64_PROJECTION
                )
            else:
                # ä¼ ç»ŸæŠ•å½±ï¼ˆfloat32ï¼‰
                points_2d = K @ vertices_cam_vis.T
                u_f = points_2d[0, :] / points_2d[2, :]
                v_f = points_2d[1, :] / points_2d[2, :]
                v_f = H - 1 - v_f
            
            in_bounds = (u_f >= 0.5) & (u_f < W-0.5) & (v_f >= 0.5) & (v_f < H-0.5)
        else:
            in_bounds = np.array([])
            u_f = np.array([])
            v_f = np.array([])
            vertices_cam_vis = np.array([])

    if np.any(visible_mask) and np.any(in_bounds):
            if not USE_GPU:
                u_f = u_f[in_bounds]
                v_f = v_f[in_bounds]
                vertices_cam_in = vertices_cam_vis[in_bounds]
            else:
                # GPUç‰ˆæœ¬å·²ç»è¿‡æ»¤
                vertices_cam_in = vertices_cam_vis[in_bounds]

            # æ·±åº¦ä¸€è‡´æ€§æ£€æµ‹
            depth_consistency_mask = np.ones(len(u_f), dtype=bool)
            if USE_DEPTH_CONSISTENCY and depth_img is not None:
                u_int = np.clip(u_f.astype(int), 0, W-1)
                v_int = np.clip(v_f.astype(int), 0, H-1)
                depth_measured = depth_img[v_int, u_int]
                depth_rendered = vertices_cam_in[:, 2]
                
                # æ ¹æ®é…ç½®é€‰æ‹©æ·±åº¦æ£€æµ‹æ–¹æ³•
                if USE_ADAPTIVE_DEPTH:
                    # è‡ªé€‚åº”æ·±åº¦æ£€æµ‹ï¼šæ ¹æ®è¡¨é¢ç±»å‹ï¼ˆåœ°é¢/å¢™å£ï¼‰ä½¿ç”¨ä¸åŒé˜ˆå€¼
                    # éœ€è¦è·å–ä¸–ç•Œåæ ‡ç³»ä¸‹çš„æ³•å‘é‡
                    valid_indices_depth = np.where(visible_mask)[0][in_bounds]
                    vertex_normals_world = normals_np[valid_indices_depth]
                    
                    # è®¡ç®—å‘ä¸Šæ–¹å‘ï¼ˆè€ƒè™‘æ—‹è½¬ï¼‰
                    R_world = R.from_euler('xyz', [final_rx, final_ry, final_rz], degrees=True).as_matrix()
                    up_vector = R_world @ np.array([0, 0, 1])  # åˆå§‹Zè½´æ—‹è½¬åˆ°ä¸–ç•Œåæ ‡
                    
                    depth_consistency_mask = adaptive_depth_test(
                        depth_rendered, depth_measured, vertex_normals_world,
                        up_vector=up_vector,
                        floor_normal_threshold=FLOOR_NORMAL_THRESHOLD,
                        floor_depth_front=FLOOR_DEPTH_FRONT,
                        floor_depth_back=FLOOR_DEPTH_BACK,
                        wall_depth_front=WALL_DEPTH_FRONT,
                        wall_depth_back=WALL_DEPTH_BACK,
                        min_depth=MIN_DEPTH,
                        max_depth=MAX_DEPTH
                    )
                else:
                    # ä¼ ç»Ÿæ·±åº¦æ£€æµ‹ï¼šä½¿ç”¨å•ä¸€é˜ˆå€¼
                    depth_diff = np.abs(depth_rendered - depth_measured)
                    depth_consistency_mask = (depth_diff < DEPTH_THRESHOLD) & \
                                             (depth_measured > MIN_DEPTH) & \
                                             (depth_measured < MAX_DEPTH)

            if not np.any(depth_consistency_mask):
                vis2.update_renderer()
                frame_count += 1
                continue

            u_f = u_f[depth_consistency_mask]
            v_f = v_f[depth_consistency_mask]
            vertices_cam_in = vertices_cam_in[depth_consistency_mask]
            
            # è½¦è¾†æ£€æµ‹ä¸å»é™¤ï¼ˆå››æ¨¡æ€å‡ ä½•æ£€æµ‹ï¼‰
            vehicle_removal_mask = np.ones(len(u_f), dtype=bool)
            if USE_VEHICLE_DETECTION and depth_img is not None:
                # åˆ›å»ºå®Œæ•´çš„æ¸²æŸ“æ·±åº¦å›¾ï¼ˆTSDFç†è®ºæ·±åº¦ï¼‰
                depth_rendered_img = np.zeros((H, W), dtype=np.float32)
                u_int_temp = np.clip(u_f.astype(int), 0, W-1)
                v_int_temp = np.clip(v_f.astype(int), 0, H-1)
                depth_rendered_temp = vertices_cam_in[:, 2]
                depth_rendered_img[v_int_temp, u_int_temp] = depth_rendered_temp
                
                # å‡†å¤‡æ³•å‘é‡å’Œ3Dç‚¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                normals_img = None
                points_3d_img = None
                
                if USE_GROUND_NORMAL or USE_HEIGHT_FILTER:
                    # åˆ›å»ºæ³•å‘é‡å’Œ3Dç‚¹çš„å›¾åƒ
                    normals_img = np.zeros((H, W, 3), dtype=np.float32)
                    points_3d_img = np.zeros((H, W, 3), dtype=np.float32)
                    
                    # ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
                    vertices_world = (T_wc_use[:3, :3] @ vertices_cam_in.T + T_wc_use[:3, 3:4]).T
                    normals_world = T_wc_use[:3, :3] @ normals_np[visible_mask][in_bounds][depth_consistency_mask].T
                    normals_world = normals_world.T
                    
                    # å¡«å……å›¾åƒ
                    normals_img[v_int_temp, u_int_temp] = normals_world
                    points_3d_img[v_int_temp, u_int_temp] = vertices_world
                
                # å››æ¨¡æ€è½¦è¾†æ£€æµ‹
                vehicle_mask_full, cue_masks = detect_vehicles_multimodal(
                    depth_obs=depth_img,
                    depth_tsdf=depth_rendered_img,
                    normals=normals_img,
                    points_3d=points_3d_img,
                    config=None  # ä½¿ç”¨å…¨å±€é…ç½®
                )
                
                # ç»†åŒ–maskï¼ˆå½¢æ€å­¦å¤„ç†ï¼‰
                vehicle_mask_full = refine_vehicle_mask(
                    vehicle_mask_full, 
                    dilation=VEHICLE_MASK_DILATION
                )
                
                # å¯é€‰ï¼šä¿å­˜vehicle maskç”¨äºè°ƒè¯•
                if SAVE_VEHICLE_MASKS and frame_count % 50 == 0:
                    mask_save_dir = Path("output/vehicle_masks")
                    mask_save_dir.mkdir(parents=True, exist_ok=True)
                    
                    # ä¿å­˜ç»¼åˆæ©ç 
                    mask_vis = (vehicle_mask_full * 255).astype(np.uint8)
                    cv2.imwrite(str(mask_save_dir / f"mask_{frame_count:04d}.png"), mask_vis)
                    
                    # ä¿å­˜å„çº¿ç´¢çš„ç‹¬ç«‹ç»“æœ
                    for cue_name, cue_mask in cue_masks.items():
                        if cue_mask is not None:
                            cue_vis = (cue_mask * 255).astype(np.uint8)
                            cv2.imwrite(str(mask_save_dir / f"cue_{cue_name}_{frame_count:04d}.png"), cue_vis)
                
                # è¿‡æ»¤æ‰è½¦è¾†åƒç´ 
                vehicle_pixel_mask = vehicle_mask_full[v_int_temp, u_int_temp]
                vehicle_removal_mask = ~vehicle_pixel_mask
                
                # ç»Ÿè®¡ä¿¡æ¯
                n_vehicle_pixels = np.sum(vehicle_pixel_mask)
                if DEBUG_MODE and n_vehicle_pixels > 0:
                    n_total = len(vehicle_pixel_mask)
                    percentage = (n_vehicle_pixels / n_total) * 100
                    print(f"      ğŸš— æ£€æµ‹è½¦è¾†åƒç´ : {n_vehicle_pixels}/{n_total} ({percentage:.1f}%)")
                    
                    # æ˜¾ç¤ºå„çº¿ç´¢è´¡çŒ®
                    if frame_count % 100 == 0:
                        for cue_name, cue_mask in cue_masks.items():
                            if cue_mask is not None:
                                cue_count = np.sum(cue_mask[v_int_temp, u_int_temp])
                                print(f"         - {cue_name}: {cue_count}/{n_total} ({cue_count/n_total*100:.1f}%)")
            
            if not np.any(vehicle_removal_mask):
                vis2.update_renderer()
                frame_count += 1
                continue
            
            u_f = u_f[vehicle_removal_mask]
            v_f = v_f[vehicle_removal_mask]
            vertices_cam_in = vertices_cam_in[vehicle_removal_mask]

            # ç¬¬4æ­¥ä¼˜åŒ–ï¼šæ™ºèƒ½è§†è§’é€‰æ‹©ä¸åŠ æƒ
            valid_indices_temp = np.where(visible_mask)[0][in_bounds][depth_consistency_mask][vehicle_removal_mask]
            
            if USE_SMART_VIEW_WEIGHTING:
                # è®¡ç®—è§†è§’è´¨é‡æƒé‡
                vertex_normals = normals_np[valid_indices_temp]
                view_dirs = -vertices_cam_in / np.linalg.norm(vertices_cam_in, axis=1, keepdims=True)
                R_cw_use = T_cw_use[:3, :3]
                normals_cam = (R_cw_use @ vertex_normals.T).T
                normals_cam = normals_cam / np.linalg.norm(normals_cam, axis=1, keepdims=True)
                
                # è§†è§’æƒé‡ï¼ˆåŸºäºæ³•å‘-è§†çº¿å¤¹è§’ï¼‰
                view_weights = compute_view_angle_weight(
                    normals_cam, view_dirs, max_angle_deg=MAX_VIEW_ANGLE_DEG
                )
                
                # è·ç¦»æƒé‡ï¼ˆåŸºäºç›¸æœºè·ç¦»ï¼‰
                distances = np.linalg.norm(vertices_cam_in, axis=1)
                dist_weights = compute_distance_weight(distances, falloff=DISTANCE_FALLOFF)
                
                # å›¾åƒè´¨é‡æƒé‡ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]ï¼‰
                if USE_IMAGE_QUALITY_FILTER and quality_score > 0:
                    # ä½¿ç”¨å½“å‰å¸§çš„è´¨é‡åˆ†æ•°ï¼ˆæ‰€æœ‰åƒç´ ç›¸åŒï¼‰
                    quality_weights = np.full(len(u_f), quality_score / 100.0)
                else:
                    quality_weights = np.ones(len(u_f))
                
                # ç»¼åˆæƒé‡
                combined_weights = compute_combined_weight(
                    view_weights, dist_weights, quality_weights,
                    view_alpha=VIEW_ANGLE_WEIGHT,
                    dist_alpha=DISTANCE_WEIGHT,
                    quality_alpha=IMAGE_QUALITY_WEIGHT
                )
                
                # è¿‡æ»¤ä½æƒé‡é‡‡æ ·
                effective_mask = combined_weights >= MIN_EFFECTIVE_WEIGHT
                
                if not np.any(effective_mask):
                    vis2.update_renderer()
                    frame_count += 1
                    continue
                
                u_f = u_f[effective_mask]
                v_f = v_f[effective_mask]
                valid_indices_temp = valid_indices_temp[effective_mask]
                angle_weights = combined_weights[effective_mask]
                
            elif USE_ANGLE_WEIGHTING:
                # ä¼ ç»Ÿè§†è§’åŠ æƒï¼ˆå‘åå…¼å®¹ï¼‰
                vertex_normals = normals_np[valid_indices_temp]
                view_dirs = -vertices_cam_in / np.linalg.norm(vertices_cam_in, axis=1, keepdims=True)
                R_cw_use = T_cw_use[:3, :3]
                normals_cam = (R_cw_use @ vertex_normals.T).T
                normals_cam = normals_cam / np.linalg.norm(normals_cam, axis=1, keepdims=True)
                cos_angles = np.sum(normals_cam * view_dirs, axis=1)
                cos_angles = np.clip(cos_angles, -1, 1)
                angles_deg = np.degrees(np.arccos(cos_angles))
                angle_mask = angles_deg < ANGLE_THRESHOLD_DEG

                if not np.any(angle_mask):
                    vis2.update_renderer()
                    frame_count += 1
                    continue

                u_f = u_f[angle_mask]
                v_f = v_f[angle_mask]
                cos_angles = cos_angles[angle_mask]
                valid_indices_temp = valid_indices_temp[angle_mask]
                angle_weights = cos_angles ** 2
            else:
                # æ— åŠ æƒ
                angle_weights = np.ones(len(u_f))

            # çº¹ç†é‡‡æ ·ï¼ˆåŒä¸‰æ¬¡æ’å€¼ æˆ– åŒçº¿æ€§æ’å€¼ï¼‰
            if USE_SUBPIXEL_PRECISION and PRESERVE_SUBPIXEL_WEIGHT:
                # ç¬¬7æ­¥ä¼˜åŒ–ï¼šä½¿ç”¨äºšåƒç´ ç²¾åº¦é‡‡æ ·ï¼ˆä¿ç•™å°æ•°ç²¾åº¦ï¼‰
                subpixel_weights = compute_subpixel_weights(u_f, v_f, mode=SUBPIXEL_WEIGHT_MODE)
                colors = sample_with_subpixel_weights(rgb_img, subpixel_weights, H, W)
            elif USE_BICUBIC_INTERPOLATION:
                # ç¬¬3æ­¥ä¼˜åŒ–ï¼šä½¿ç”¨åŒä¸‰æ¬¡æ’å€¼ï¼ˆæ›´é«˜è´¨é‡ï¼‰
                colors = bicubic_interpolate(rgb_img, u_f, v_f, a=BICUBIC_A)
            else:
                # ä¼ ç»ŸåŒçº¿æ€§æ’å€¼
                u0 = np.floor(u_f).astype(int)
                v0 = np.floor(v_f).astype(int)
                u1 = np.minimum(u0 + 1, W - 1)
                v1 = np.minimum(v0 + 1, H - 1)
                wu = u_f - u0
                wv = v_f - v0
                c00 = rgb_img[v0, u0]
                c10 = rgb_img[v0, u1]
                c01 = rgb_img[v1, u0]
                c11 = rgb_img[v1, u1]
                colors = (c00 * (1-wu)[:, np.newaxis] * (1-wv)[:, np.newaxis] +
                          c10 *  wu[:, np.newaxis] * (1-wv)[:, np.newaxis] +
                          c01 * (1-wu)[:, np.newaxis] *  wv[:, np.newaxis] +
                          c11 *  wu[:, np.newaxis] *  wv[:, np.newaxis])

            # åŠ æƒèåˆ
            valid_indices = valid_indices_temp
            vertex_colors[valid_indices] += colors * angle_weights[:, np.newaxis]
            vertex_weights[valid_indices] += angle_weights

            # æ›´æ–°é¢œè‰²ï¼ˆé™ä½æ›´æ–°é¢‘ç‡ä»¥æé«˜GPUåˆ©ç”¨ç‡ï¼‰
            if frame_count % VISUALIZATION_UPDATE_RATE == 0:
                current_colors = initial_colors.copy()
                non_zero = vertex_weights > 0
                current_colors[non_zero] = vertex_colors[non_zero] / vertex_weights[non_zero, np.newaxis]
                mesh.vertex_colors = o3d.utility.Vector3dVector(current_colors)
                vis2.update_geometry(mesh)

    vis2.update_renderer()
    frame_count += 1
    progress = frame_count / len(texture_sampled_indices) * 100
    colored_vertices = np.sum(vertex_weights > 0)
    coverage = colored_vertices / len(vertices_np) * 100

    if DEBUG_MODE and frame_count <= 5:
        cam_x = T_wc_use[:3, 0]
        cam_y = T_wc_use[:3, 1]
        cam_z = T_wc_use[:3, 2]
        print(f"\n  [è°ƒè¯• å¸§{fid}]")
        print(f"    - ç›¸æœºä½ç½®: [{cam_pos[0]:.2f}, {cam_pos[1]:.2f}, {cam_pos[2]:.2f}]")
        print(f"    - Xè½´(çº¢): [{cam_x[0]:.3f}, {cam_x[1]:.3f}, {cam_x[2]:.3f}]")
        print(f"    - Yè½´(ç»¿): [{cam_y[0]:.3f}, {cam_y[1]:.3f}, {cam_y[2]:.3f}]")
        print(f"    - Zè½´(è“): [{cam_z[0]:.3f}, {cam_z[1]:.3f}, {cam_z[2]:.3f}]")
        if USE_GPU:
            mem_used, mem_total = check_gpu_memory()
            print(f"    - GPUæ˜¾å­˜: {mem_used:.2f} / {mem_total:.1f} GB")

    # è¿›åº¦æ˜¾ç¤º
    elapsed_time = time.time() - start_time
    fps = frame_count / elapsed_time if elapsed_time > 0 else 0
    eta = (len(texture_sampled_indices) - frame_count) / fps if fps > 0 else 0
    
    progress_str = f"\r  [{frame_count}/{len(texture_sampled_indices)}] {progress:.1f}% | " \
                   f"è¦†ç›–: {coverage:.1f}% | " \
                   f"å¸§{fid:04d} | "
    
    if USE_GPU:
        mem_used, mem_total = check_gpu_memory()
        mem_usage_pct = (mem_used / mem_total * 100) if mem_total > 0 else 0
        progress_str += f"ğŸš€GPU: {mem_used:.1f}/{mem_total:.1f}GB ({mem_usage_pct:.0f}%) | "
    else:
        progress_str += f"ğŸ’»CPU | "
    
    progress_str += f"{fps:.1f}fps | ETA: {eta:.0f}s"
    print(progress_str, end="", flush=True)

    time.sleep(UPDATE_INTERVAL)

print("\n\n" + "="*70)
print("[SUCCESS] OpenMVSå¢å¼ºçº¹ç†åŒ–å®Œæˆ!")
print("="*70)

# ä»GPUä¸‹è½½æœ€ç»ˆç»“æœ
if USE_GPU:
    print(f"\nğŸ“¥ é‡Šæ”¾GPUèµ„æº...")
    # æ¸…ç†GPUå†…å­˜
    del vertices_gpu
    del normals_gpu
    del K_gpu
    if vertex_colors_gpu is not None:
        del vertex_colors_gpu
    if vertex_weights_gpu is not None:
        del vertex_weights_gpu
    if cp is not None:
        mempool = cp.get_default_memory_pool()
        mempool.free_all_blocks()
    print(f"   âœ“ GPUå†…å­˜å·²é‡Šæ”¾")

# ============================================================================
# ç¬¬5æ­¥ä¼˜åŒ–ï¼šæ¥ç¼å¹³æ»‘åå¤„ç†
# ============================================================================
n_seam_vertices = 0  # åˆå§‹åŒ–æ¥ç¼é¡¶ç‚¹æ•°
seam_ratio = 0.0

if USE_SEAM_SMOOTHING:
    print(f"\nğŸ¨ åº”ç”¨æ¥ç¼å¹³æ»‘ï¼ˆç¬¬5æ­¥ä¼˜åŒ–ï¼‰...")
    seam_start_time = time.time()
    
    # æ£€æµ‹æ¥ç¼åŒºåŸŸ
    print(f"   [1/3] æ£€æµ‹æ¥ç¼åŒºåŸŸ...")
    seam_mask, variances = detect_seam_regions(
        mesh, vertex_colors, vertex_weights,
        variance_threshold=VARIANCE_THRESHOLD,
        k_neighbors=SEAM_K_NEIGHBORS
    )
    
    n_seam_vertices = np.sum(seam_mask)
    seam_ratio = n_seam_vertices / len(vertices_np) * 100
    print(f"         âœ“ æ£€æµ‹åˆ° {n_seam_vertices:,} ä¸ªæ¥ç¼é¡¶ç‚¹ ({seam_ratio:.1f}%)")
    
    if n_seam_vertices > 0:
        # åº”ç”¨å¹³æ»‘
        print(f"   [2/3] åº”ç”¨è‡ªé€‚åº”å¹³æ»‘...")
        smoothed_colors = apply_adaptive_smoothing(
            mesh, vertex_colors, vertex_weights, seam_mask,
            smoothing_strength=SMOOTHING_STRENGTH,
            k_neighbors=SEAM_K_NEIGHBORS
        )
        
        # æ›´æ–°é¡¶ç‚¹é¢œè‰²
        print(f"   [3/3] æ›´æ–°ç½‘æ ¼é¢œè‰²...")
        mesh.vertex_colors = o3d.utility.Vector3dVector(smoothed_colors)
        
        seam_time = time.time() - seam_start_time
        print(f"   âœ“ æ¥ç¼å¹³æ»‘å®Œæˆ! è€—æ—¶: {seam_time:.2f}ç§’")
    else:
        print(f"   â„¹ æœªæ£€æµ‹åˆ°æ˜æ˜¾æ¥ç¼ï¼Œè·³è¿‡å¹³æ»‘")
else:
    # ä¸ä½¿ç”¨æ¥ç¼å¹³æ»‘ï¼Œç›´æ¥å½’ä¸€åŒ–é¡¶ç‚¹é¢œè‰²
    final_colors = initial_colors.copy()
    non_zero = vertex_weights > 0
    final_colors[non_zero] = vertex_colors[non_zero] / vertex_weights[non_zero, np.newaxis]
    mesh.vertex_colors = o3d.utility.Vector3dVector(final_colors)

# ============================================================================
# åå¤„ç†ï¼šå¡«å……ç©ºç™½åŒºåŸŸï¼ˆè½¦è¾†é®æŒ¡å¯¼è‡´çš„æœªæŠ•å½±åŒºåŸŸï¼‰
# ============================================================================
if FILL_EMPTY_VERTICES and USE_VEHICLE_REMOVAL:
    print(f"\nğŸ¨ å¡«å……ç©ºç™½åŒºåŸŸï¼ˆåå¤„ç†ï¼‰...")
    fill_start_time = time.time()
    
    # è·å–å½“å‰é¢œè‰²å’Œæƒé‡
    current_colors = np.asarray(mesh.vertex_colors)
    
    # ä½¿ç”¨Kè¿‘é‚»å¡«å……
    if FILL_METHOD == 'knn':
        filled_colors = fill_empty_vertices(
            current_colors, 
            vertex_weights, 
            vertices_np,
            k=KNN_NEIGHBORS
        )
        mesh.vertex_colors = o3d.utility.Vector3dVector(filled_colors)
    
    fill_time = time.time() - fill_start_time
    print(f"   âœ“ å¡«å……å®Œæˆ! è€—æ—¶: {fill_time:.2f}ç§’")
elif FILL_EMPTY_VERTICES and not USE_VEHICLE_REMOVAL:
    print(f"\nâš ï¸  å¡«å……ç©ºç™½åŒºåŸŸéœ€è¦å¯ç”¨è½¦è¾†å»é™¤åŠŸèƒ½")

colored_vertices = np.sum(vertex_weights > 0)
coverage = colored_vertices / len(vertices_np) * 100
total_time = time.time() - start_time
avg_fps = frame_count / total_time if total_time > 0 else 0

print(f"\næœ€ç»ˆç»Ÿè®¡:")
print(f"  - è®¡ç®—è®¾å¤‡: {'ğŸš€ GPUåŠ é€Ÿ' if USE_GPU else 'ğŸ’» CPU'}")
print(f"  - å¤„ç†å¸§æ•°: {frame_count}")

# æ˜¾ç¤ºå›¾åƒè´¨é‡ç»Ÿè®¡
if USE_IMAGE_QUALITY_FILTER and quality_stats['total_frames'] > 0:
    print(f"\nå›¾åƒè´¨é‡ç»Ÿè®¡ï¼ˆç¬¬1æ­¥ä¼˜åŒ–ï¼‰:")
    print(f"  - æ£€æŸ¥å¸§æ•°: {quality_stats['total_frames']}")
    print(f"  - é€šè¿‡å¸§æ•°: {quality_stats['processed_frames']} ({quality_stats['processed_frames']/quality_stats['total_frames']*100:.1f}%)")
    print(f"  - è·³è¿‡å¸§æ•°: {quality_stats['total_frames'] - quality_stats['processed_frames']} ({(quality_stats['total_frames'] - quality_stats['processed_frames'])/quality_stats['total_frames']*100:.1f}%)")
    print(f"    â””â”€ æ¨¡ç³Š: {quality_stats['skipped_blur']}")
    print(f"    â””â”€ è¿‡æ›: {quality_stats['skipped_overexp']}")
    print(f"    â””â”€ æ¬ æ›: {quality_stats['skipped_underexp']}")
    print(f"    â””â”€ è´¨é‡ä½: {quality_stats['skipped_quality']}")
    if quality_stats['avg_quality']:
        print(f"  - å¹³å‡è´¨é‡åˆ†æ•°: {np.mean(quality_stats['avg_quality']):.1f}")
        print(f"  - å¹³å‡æ¸…æ™°åº¦: {np.mean(quality_stats['avg_sharpness']):.1f}")
print(f"  - æ€»è€—æ—¶: {total_time:.1f}ç§’")
print(f"  - å¹³å‡é€Ÿåº¦: {avg_fps:.2f} fps")
print(f"  - æ¯å¸§è€—æ—¶: {total_time/frame_count*1000:.1f} ms") if frame_count > 0 else None
print(f"  - ç€è‰²é¡¶ç‚¹: {colored_vertices:,}")
print(f"  - è¦†ç›–ç‡: {coverage:.1f}%")
print(f"  - æ·±åº¦ä¸€è‡´æ€§: {'å·²å¯ç”¨' if USE_DEPTH_CONSISTENCY else 'æœªå¯ç”¨'}")
if USE_SMART_VIEW_WEIGHTING:
    print(f"  - æ™ºèƒ½è§†è§’åŠ æƒ: å·²å¯ç”¨ (ç¬¬4æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ æƒé‡: è§†è§’{VIEW_ANGLE_WEIGHT:.0%} + è·ç¦»{DISTANCE_WEIGHT:.0%} + è´¨é‡{IMAGE_QUALITY_WEIGHT:.0%}")
elif USE_ANGLE_WEIGHTING:
    print(f"  - ä¼ ç»Ÿè§†è§’åŠ æƒ: å·²å¯ç”¨")
else:
    print(f"  - è§†è§’åŠ æƒ: æœªå¯ç”¨")
if USE_SEAM_SMOOTHING and n_seam_vertices > 0:
    print(f"  - æ¥ç¼å¹³æ»‘: å·²å¯ç”¨ (ç¬¬5æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ å¹³æ»‘é¡¶ç‚¹: {n_seam_vertices:,} ({seam_ratio:.1f}%), å¼ºåº¦: {SMOOTHING_STRENGTH:.0%}")
elif USE_SEAM_SMOOTHING:
    print(f"  - æ¥ç¼å¹³æ»‘: å·²å¯ç”¨ (æœªæ£€æµ‹åˆ°æ¥ç¼)")
else:
    print(f"  - æ¥ç¼å¹³æ»‘: æœªå¯ç”¨")
print(f"  - æ›å…‰è¡¥å¿: {'å·²å¯ç”¨' if USE_EXPOSURE_COMP else 'æœªå¯ç”¨'}")
print(f"  - çº¹ç†æ’å€¼: {'åŒä¸‰æ¬¡ (æ›´é«˜è´¨é‡)' if USE_BICUBIC_INTERPOLATION else 'åŒçº¿æ€§'}")

# ç¬¬6æ­¥ä¼˜åŒ–ç»“æŸç»Ÿè®¡
if USE_LAB_COLOR_SPACE:
    print(f"  - LABè‰²å½©ç©ºé—´: å·²å¯ç”¨ (ç¬¬6æ­¥ä¼˜åŒ–)")
    print(f"    â””â”€ ç”¨äºæ¥ç¼å¹³æ»‘çš„é¢œè‰²æ··åˆ")
else:
    print(f"  - LABè‰²å½©ç©ºé—´: æœªå¯ç”¨ (ä½¿ç”¨RGBç©ºé—´)")

if USE_GPU:
    print(f"\nğŸ’¡ æç¤º: GPUåŠ é€Ÿæ¨¡å¼å¯æä¾›3-6å€æ€§èƒ½æå‡")
print(f"\nçª—å£ä¿æŒæ‰“å¼€ï¼ŒæŒ‰ Q æˆ– ESC å…³é—­")

vis2.run()
vis2.destroy_window()

# ============================================================================
# ä¿å­˜çº¹ç†åŒ–åçš„æ¨¡å‹
# ============================================================================
if SAVE_TEXTURED_MESH:
    print("\n" + "="*70)
    print("ä¿å­˜çº¹ç†åŒ–æ¨¡å‹")
    print("="*70)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    from pathlib import Path
    output_dir = Path(OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if AUTO_TIMESTAMP:
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
        filename_base, ext = OUTPUT_FILENAME.rsplit('.', 1) if '.' in OUTPUT_FILENAME else (OUTPUT_FILENAME, 'ply')
        output_filename = f"{filename_base}_{timestamp}.{ext}"
    else:
        output_filename = OUTPUT_FILENAME
    
    output_path = output_dir / output_filename
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {output_path}")
    try:
        success = o3d.io.write_triangle_mesh(str(output_path), mesh, write_vertex_colors=True)
        if success:
            print(f"âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ!")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            n_vertices = len(np.asarray(mesh.vertices))
            n_triangles = len(np.asarray(mesh.triangles))
            has_colors = mesh.has_vertex_colors()
            print(f"\næ¨¡å‹ç»Ÿè®¡:")
            print(f"  - é¡¶ç‚¹æ•°: {n_vertices:,}")
            print(f"  - ä¸‰è§’å½¢æ•°: {n_triangles:,}")
            print(f"  - é¡¶ç‚¹é¢œè‰²: {'æ˜¯' if has_colors else 'å¦'}")
            
            # æ–‡ä»¶å¤§å°
            file_size = output_path.stat().st_size / (1024 * 1024)  # MB
            print(f"  - æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        else:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥!")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")

print("\n" + "="*70)



